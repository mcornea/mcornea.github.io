<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>remote-lab.net</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">        
        <meta name="description" content="Harmony is a free responsive jekyll theme by Gayan Virajith and Maheshika Lakmali. Sourced on Github -  https://github.com/gayanvirajith/harmony
">
        <link rel="canonical" 
        href="http://remoteur.github.io//">
        
        <!-- Harmony styles -->
        <link rel="stylesheet" type="text/css" href="http://remoteur.github.io/assets/css/main.css">

        <!-- Modernizr js -->
        <script async src="http://remoteur.github.io/assets/js/modernizr.js"></script>    

        <!-- IE Fixes -->
        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->        
    </head>
    <body class="theme-base-01">
        <header class="main-header">
            <div class="wc-container">
                <h1><a href="http://remoteur.github.io/">remote-lab.net</a></h1>
                <h2>learn by doing</h2>
                <ul>
	<li>
		<a href="http://remoteur.github.io">Home</a><span>/</span>
	</li>
	<li>
		<a href="http://remoteur.github.io//about">About</a><span>/</span>
	</li>
	<li>
		<a href="http://remoteur.github.io//blog">Blog</a><span>/</span>
	</li>
	<li>
		<a href="https://compute.remote-lab.net" target="_blank">Compute</a><span>/</span>
	</li>
</ul>
                
            </div>
        </header>
        <div id="home" class="page-content wc-container">
	<div class="posts">
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//uncategorized/linux/virtualization/python/2015/04/05/getting-started-with-docker-and-the-wonders-of-opensource/">
			        Getting started with Docker and the wonders of Open Source
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            uncategorized, linux, virtualization, and python
            </span> |
            
            <span class="post-date">
            Apr 5, 2015 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>As Docker has been a buzzword lately(last year or so) I though that I should give it a try and really do something with it besides reading articles about how great it is. First thing that came to mind and most handy I guess is to build a LAMP stack environment for Wordpress sites. So how do I start? Well, let's take the LAMP environment and split it into components: we need a database to store data and a web server that can process the Wordpress PHP code. Based on this I decided to create a container for the MySQL database and a container for running Apache plus additional PHP modules. Then I would also like to run multiple Wordpress instances on the same server to make use of all the resources. In order to achieve isolation between the apps we can create separate containers for each WP instance, each with its own database on the MySQL server. Nevertheless since we want all the instances accessible by a single IP address, we also need a load balancer that routes traffic to the webserver containers according to the Host field in the HTTP header. </p>
<p>Below is a diagram that better describes the flow:<br />
<a href="https://remote-lab.net/wp-content/uploads/2015/04/Containers-start-New-Page1.png"><img src="https://remote-lab.net/wp-content/uploads/2015/04/Containers-start-New-Page1.png" alt="Containers start - New Page" width="1167" height="657" class="aligncenter size-full wp-image-303" /></a></p>
<p>So, let's get started. I got a Fedora21 instance powered up and followed the documentation <a href="https://docs.docker.com/installation/fedora/">here</a>[1] to get Docker up and running. Once I got the docker environment ready I started searching for some examples that would quickly get me started with the apps that I needed. So I started with the MySQL server. A quick search on Google pointed me to the official MySQL <a href="https://registry.hub.docker.com/_/mysql/">repo</a>[2] on Docker Hub that contains pretty straight forward documentation on how to get a running MySQL container. </p>
<p>Here's the command that I ran in order to get it running:<br />
<code lang="python[notools]"><br />
docker run --name db-server -v /srv/db-server/storage:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=$(openssl rand -hex 10) -d mysql:latest<br />
</code></p>
<p>What this does is that it creates a container called db-server with the /var/lib/mysql directory mounted from the /srv/db-server/storage directory on the host file system, injecting the MYSQL_ROOT_PASSWORD(some random generated hex string) environment variable that will be used at database server initialization and it uses the image called mysql(pulled from Docker hub) with the tag latest to build from. I chose storing the mysql content to a directory accessible on the host because I am not familiar yet with the Docker images and file system and I would like to preserve the db data in case I mess up something with the containers. Now that we ran the command we should see the container running:</p>
<p><code lang="python[notools]">root@docker:~&gt;&gt; docker ps<br />
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES<br />
c383c56a7e66        mysql:latest        "/entrypoint.sh mysq   About an hour ago   Up 7 seconds        3306/tcp            db-server</code>         </p>
<p>We can see that the server is running and it's exposing the MySQL port 3306. You can check the container properties by running 'docker inspect db-server'. This should return a json containing all the container properties including the environment variables that were set at start, including the MySQL root password. </p>
<p>We can actually check the current databases by running this dirty one liner:<br />
<code lang="python[notools]">root@docker:~&gt;&gt; docker exec db-server mysql -uroot -p`docker inspect --format '' db-server | awk {'print $1'} | awk -F '=' {'print $2'}` -e 'show databases'<br />
Database<br />
information_schema<br />
domain<br />
mysql<br />
performance_schema</code></p>
<p>So now that we have the DB server ready we can proceed further with creating the Apache webserver. First thing before reinventing the wheel is to search if others already created the wheel. As expected I found John Finks docker-wordpress repo <a href="https://github.com/jbfink/docker-wordpress.git">here</a>[3] where he covers a full LAMP stack, including Wordpress container. I didn't need all that for my webserver containers but it was a great starting point for me. So I forked it, did some changes and it resulted in the following <a href="https://github.com/remoteur/docker-wordpress.git">repo</a>. Let's take a look at what's inside the repo. We have a Dockerfile and 2 directories: configs and scripts. The 2 directories actually contain files that are called in the Dockerfile. What is this Dockerfile? It's the file used for building Docker images. Usually it contains a base image and some additional steps that are ran on top of the base image. For instance my Dockerfile uses the Debian image tagged latest as base, then it adds the Dotdeb repos, installs the packages required for Apache and PHP modules, adds the config files from the config directory inside the image and also the files from the scripts directory that are going to be run when the container starts. Let's build the image by using this Dockerfile. </p>
<p><code lang="python[notools]">root@docker:~&gt;&gt; git clone https://github.com/remoteur/docker-wordpress.git<br />
root@docker:~&gt;&gt; cd docker-wordpress/<br />
root@docker:~/docker-wordpress&gt;&gt; docker build -t webnode .</code></p>
<p>It takes some time to build the image and after it's finished we can go ahead and fire up the webnode container. </p>
<p><code lang="python[notools]">root@docker:~&gt;&gt; docker run --name webnode  -v /srv/webnode/www:/var/www/ --link db-server:mysql -d webnode:latest</code></p>
<p>What this does is that it runs a container called webnode which is linked to the db-server container so that it can access it by it's name (mysql in our example) and it's using the image that we've just built called webnode with the 'latest' tag. Again we want the data that's important to us from the container to be stored directly on the host file system so we mount the /var/www directory from the host's /srv/webnode/www directory. We can now see both the containers are running:</p>
<p><code lang="python[notools]">root@docker:~&gt;&gt; docker ps<br />
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES<br />
4aba6d289230        webnode:latest      "/bin/bash /start.sh   3 minutes ago       Up 3 minutes        80/tcp              webnode<br />
c383c56a7e66        mysql:latest        "/entrypoint.sh mysq   2 hours ago         Up 32 minutes       3306/tcp            db-server  </code>         </p>
<p>At this point we have the database server and webserver running but without any content in the Apache root directory. So in order to get Wordpress automatically installed when running a webnode container I wrote a quick bash script that creates the requirements for the Wordpress instance such as database, database user, pulls the latest Wordpress  and adjusts the wp-config.php file so it matches the db settings. You may find the script <a href="https://gist.github.com/remoteur/6b12ce450d0005acc287">here</a>[5]</p>
<p>After running the container by using this script we have a full runing LAMP environment with Wordpress code installed in the Apache root. The only thing that we're missing is the load balancer container that will acutally expose the websites publicly by the hosts IP address and route traffic to the webnode containers. Basically this could be done by installing an Nginx container that acts as a reverse proxy. But then we'd need to adjust the Nginx configuration files manually which we don't want because we hate doing manual operations, right? :) So next step is to search for how others do this, I'm pretty sure I'm not the first one that hit this issue. My searches brought me to Jason Wilder nginx-proxy github <a href="https://github.com/jwilder/nginx-proxy.git">repo</a>[6] which does exactly what I need. Basically the repo contains a Dockerfile that installs nginx plus docker-gen. Docker-gen is a tool that generates files based on templates and docker containers metadata. What this does in our case is that it watches for containers that are ran with the VIRTUAL_HOST env var set, generates the nginx config file containing the server directive with the values passed through VIRTUAL_HOST and reloads the nginx service in the end. That's pretty awesome so let's start it:</p>
<p><code lang="python[notools]">root@docker:~&gt;&gt; docker run --name loadbalancer -d -p 80:80 -v /var/run/docker.sock:/tmp/docker.sock jwilder/nginx-proxy</code></p>
<p>The command runs a container called loadbalancer with it's port 80 translated to the host's port 80(listening on all interfaces), the Docker socket file on the host(/var/run/docker.sock) is accessible inside the container by /tmp/docker.sock and it's using the jwilder/nginx-proxy image to run from. We should now be able to create a new webnode container and access it via the the hosts IP address on port 80. Let's give it a try and see if it works:</p>
<p><code lang="python[notools]">root@docker:~&gt;&gt; bash create_wordpress<br />
Enter wordress domain:<br />
domain.com<br />
Creating container web root in /srv/webnode/webnode-domain.com/www<br />
Downloading Wordpress to webnode-domain.com<br />
Creating Wordpress database<br />
Adjusting wp-config.php<br />
Adjusting permissions for www-data<br />
c9f7ebb1935f60c293d6feddfb436321afb9b5d1b57800da62d77d49a292dbdb
<p>root@docker:~&gt;&gt; docker ps<br />
CONTAINER ID        IMAGE                        COMMAND                CREATED             STATUS              PORTS                         NAMES<br />
c9f7ebb1935f        webnode:latest               "/bin/bash /start.sh   34 seconds ago      Up 31 seconds       80/tcp                        webnode-domain.com<br />
812324707acd        jwilder/nginx-proxy:latest   "forego start -r"      8 minutes ago       Up 8 minutes        443/tcp, 0.0.0.0:80-&gt;80/tcp   loadbalancer<br />
4aba6d289230        webnode:latest               "/bin/bash /start.sh   39 minutes ago      Up 39 minutes       80/tcp                        webnode<br />
c383c56a7e66        mysql:latest                 "/entrypoint.sh mysq   2 hours ago         Up About an hour    3306/tcp                      db-server            </p>
<p>And the result:<br />
<a href="https://remote-lab.net/wp-content/uploads/2015/04/Screenshot-from-2015-04-05-212408.png"><img src="https://remote-lab.net/wp-content/uploads/2015/04/Screenshot-from-2015-04-05-212408.png" alt="Screenshot from 2015-04-05 21:24:08" width="1430" height="847" class="aligncenter size-full wp-image-304" /></a></p>
<p>That's pretty awesome given the fact that I was able to do this in a couple of hours on a lazy Sunday. I'm pretty sure Docker has its caveats (building images takes such a long time) but it's amazing how fast you can achieve this kind of automation and get familiar with the technology. Long live the Open Source community! :)</p>
<p><code lang="python[notools]">[1] https://docs.docker.com/installation/fedora/<br />
[2] https://registry.hub.docker.com/_/mysql/<br />
[3] https://github.com/jbfink/docker-wordpress.git<br />
[4] https://github.com/remoteur/docker-wordpress.git<br />
[5] https://gist.github.com/remoteur/6b12ce450d0005acc287<br />
[6] https://github.com/jwilder/nginx-proxy.git</code></p>


</code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//uncategorized/linux/virtualization/python/2015/04/05/getting-started-with-docker-and-the-wonders-of-opensource/" title="Getting started with Docker and the wonders of Open Source">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//uncategorized/linux/routing/ios/python/2015/02/24/ospf-lab-provisioning-on-ios-with-ansible/">
			        OSPF lab provisioning on IOS with Ansible
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            uncategorized, linux, routing, ios, and python
            </span> |
            
            <span class="post-date">
            Feb 24, 2015 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>In this post we'll see how we can quickly get a basic OSPF lab deployed by using Ansible. Our setup consists of 3 x Cisco IOS routers which are connected according to the diagram below. All the routers should already have SSH set up and an interface connected to the management network that will be used for retrieving the configuration files from the server. On the server side we need a Linux machine that has Ansible installed.</p>
<p><a href="https://remote-lab.net/wp-content/uploads/2015/02/ansible_ospf-New-Page.png"><img src="https://remote-lab.net/wp-content/uploads/2015/02/ansible_ospf-New-Page.png" alt="ansible_ospf - New Page" width="649" height="594" class="aligncenter size-full wp-image-297" /></a></p>
<p>So let's get started by building the Ansible playbook. I'll explain the site.yml file below: </p>
<p>1. Run the playbook on the 'localhost' server by using the 'marius' username with sudo<br />
2. Install and start Apache as the routers will pull the config files over HTTP<br />
3. Install Git - used to clone the netmiko library repo<br />
4. Install paramiko - dependency library for netmiko<br />
5. Clone the netmiko repo and install it as a system module<br />
6. Next we use the netmiko.j2 template to create a script file. The script uses netmiko and takes as arguments the ip address, username, password and command that will be run on the remote Cisco device.<br />
7. We generate the configuration files that are going to be pulled by the routers. For this we use the config.j2 template and write the configuration files on the Apache DocumentRoot. This will results in 3 files: /var/www/html/rtr-A.config, /var/www/html/rtr-B.config, /var/www/html/rtr-C.config containing the configuration commands for each of the routers.<br />
8. We run the script that we have created on step 6 by passing the 'copy http://... running-config' command to each of the routers.<br />
9. Define the variables used in the template files and commands.</p>
<p><code lang="bash[notools]"><br />
---<br />
- hosts: localhost<br />
  remote_user: marius<br />
  sudo: yes
<p>  tasks:<br />
  - name: Install Apache<br />
    yum: name=httpd state=installed</p>
<p>  - name: Start Apache<br />
    service: name=httpd state=started enabled=yes</p>
<p>  - name: Install Git<br />
    yum: name=git state=installed</p>
<p>  - name: Install paramiko<br />
    yum: name=python-paramiko state=installed</p>
<p>  - name: Clone netmiko<br />
    git: repo=https://github.com/ktbyers/netmiko.git dest=/opt/netmiko</p>
<p>  - name: Install netmiko<br />
    command: chdir=/opt/netmiko python setup.py install</p>
<p>  - name: Create netmiko script<br />
    template: src=netmiko.j2 dest=/opt/remote_cmd</p>
<p>  - name: Generate config file<br />
    template: src=config.j2 dest=/var/www/html/.config<br />
    with_items: routers</p>
<p>  - name: Connect to routers and pull the config<br />
    shell: python /opt/remote_cmd    'copy http:///.config running-config'<br />
    with_items: routers</p>
<p>  vars:<br />
   routers:<br />
     - name: "rtr-A"<br />
       mgmt_ip: "192.168.0.81"<br />
       mgmt_user: "admin"<br />
       mgmt_pass: "parola"<br />
       int:<br />
         - name: "GigabitEthernet0/1"<br />
           address: "10.0.0.1"<br />
           netmask: "255.255.255.252"<br />
           ospf: "yes"<br />
         - name: "GigabitEthernet0/2"<br />
           address: "10.0.0.5"<br />
           netmask: "255.255.255.252"<br />
           ospf: "yes"<br />
         - name: "Loopback0"<br />
           address: "1.1.1.1"<br />
           netmask: "255.255.255.0"<br />
           ospf: "yes"</p>
<p>     - name: "rtr-B"<br />
       mgmt_ip: "192.168.0.78"<br />
       mgmt_user: "admin"<br />
       mgmt_pass: "parola"<br />
       int:<br />
        - name: "GigabitEthernet0/1"<br />
          address: "10.0.0.2"<br />
          netmask: "255.255.255.252"<br />
          ospf: "yes"<br />
        - name: "GigabitEthernet0/2"<br />
          address: "10.0.0.9"<br />
          netmask: "255.255.255.252"<br />
          ospf: "yes"<br />
        - name: "Loopback0"<br />
          address: "2.2.2.2"<br />
          netmask: "255.255.255.0"<br />
          ospf: "yes"</p>
<p>     - name: "rtr-C"<br />
       mgmt_ip: "192.168.0.79"<br />
       mgmt_user: "admin"<br />
       mgmt_pass: "parola"<br />
       int:<br />
         - name: "GigabitEthernet0/1"<br />
           address: "10.0.0.6"<br />
           netmask: "255.255.255.252"<br />
           ospf: "yes"<br />
         - name: "GigabitEthernet0/2"<br />
           address: "10.0.0.10"<br />
           netmask: "255.255.255.252"<br />
           ospf: "yes"<br />
         - name: "Loopback0"<br />
           address: "3.3.3.3"<br />
           netmask: "255.255.255.0"<br />
           ospf: "no" </p>
<p>Now let's go through the template files. </p>
<p>The config.j2 template is used to build the configuration commands that will be loaded by the routers. What this does is basically loop through the interfaces defined for each of the routers and create the ip address statements for each of them. After this, it generates an entry for the ospf process and creates a network statement if the 'ospf' variable is set to yes for a specific interface. </p>
<p><code lang="bash[notools]"><br />
config.j2<br />

<p>router ospf 1<br />
</p>
<p>The netmiko.j2 template is just a python script that's using netmiko to connect to the router, first runs 'file prompt quiet' configuration command to disable the save confirmation message. Then it runs the command that's passed as the 4th argument.  </p>
<p><code lang="bash[notools]"><br />
netmiko.j2<br />
#!/usr/bin/env python<br />
import netmiko<br />
import sys
<p>cisco_881 = {<br />
	'device_type': 'cisco_ios',<br />
	'ip':   sys.argv[1],<br />
	'username': sys.argv[2],<br />
	'password': sys.argv[3],<br />
	'secret': 'secret',<br />
	'verbose': False,<br />
}</p>
<p>SSHClass = netmiko.ssh_dispatcher(device_type=cisco_881['device_type'])</p>
<p>net_connect = SSHClass(**cisco_881)</p>
<p>config_commands = [ 'file prompt quiet' ]<br />
output = net_connect.send_config_set(config_commands)</p>
<p>output = net_connect.send_command(sys.argv[4])<br />
</p>
<p>In order to run this we will also need the /etc/ansible/hosts file to contain the localhost hostname. You can find all the files in this GitHub repo: <a href="https://github.com/remoteur/ansible-ospflab.git">https://github.com/remoteur/ansible-ospflab.git</a></p>
<p>Once we have all the files in place we can run the playbook by the 'ansible-playbook site.yml' command. This is how the output looks like:</p>
<p><code lang="bash[notools]"><br />
marius@net-master:/etc/ansible&gt;&gt;&gt; ansible-playbook site.yml 
<p>PLAY [localhost] ************************************************************** </p>
<p>GATHERING FACTS ***************************************************************<br />
ok: [localhost]</p>
<p>TASK: [Install Apache] ********************************************************<br />
ok: [localhost]</p>
<p>TASK: [Start Apache] **********************************************************<br />
ok: [localhost]</p>
<p>TASK: [Install Git] ***********************************************************<br />
ok: [localhost]</p>
<p>TASK: [Install paramiko] ******************************************************<br />
ok: [localhost]</p>
<p>TASK: [Clone netmiko] *********************************************************<br />
ok: [localhost]</p>
<p>TASK: [Install netmiko] *******************************************************<br />
changed: [localhost]</p>
<p>TASK: [Create netmiko script] *************************************************<br />
ok: [localhost]</p>
<p>TASK: [Generate config file] **************************************************<br />
ok: [localhost] =&gt; (item={'mgmt_pass': 'parola', 'int': [{'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/1', 'address': '10.0.0.1'}, {'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/2', 'address': '10.0.0.5'}, {'netmask': '255.255.255.0', 'ospf': 'yes', 'name': 'Loopback0', 'address': '1.1.1.1'}], 'name': 'rtr-A', 'mgmt_ip': '192.168.0.81', 'mgmt_user': 'admin'})<br />
ok: [localhost] =&gt; (item={'mgmt_pass': 'parola', 'int': [{'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/1', 'address': '10.0.0.2'}, {'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/2', 'address': '10.0.0.9'}, {'netmask': '255.255.255.0', 'ospf': 'yes', 'name': 'Loopback0', 'address': '2.2.2.2'}], 'name': 'rtr-B', 'mgmt_ip': '192.168.0.78', 'mgmt_user': 'admin'})<br />
ok: [localhost] =&gt; (item={'mgmt_pass': 'parola', 'int': [{'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/1', 'address': '10.0.0.6'}, {'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/2', 'address': '10.0.0.10'}, {'netmask': '255.255.255.0', 'ospf': 'no', 'name': 'Loopback0', 'address': '3.3.3.3'}], 'name': 'rtr-C', 'mgmt_ip': '192.168.0.79', 'mgmt_user': 'admin'})</p>
<p>TASK: [Connect to routers and pull the config] ********************************<br />
changed: [localhost] =&gt; (item={'mgmt_pass': 'parola', 'int': [{'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/1', 'address': '10.0.0.1'}, {'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/2', 'address': '10.0.0.5'}, {'netmask': '255.255.255.0', 'ospf': 'yes', 'name': 'Loopback0', 'address': '1.1.1.1'}], 'name': 'rtr-A', 'mgmt_ip': '192.168.0.81', 'mgmt_user': 'admin'})<br />
changed: [localhost] =&gt; (item={'mgmt_pass': 'parola', 'int': [{'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/1', 'address': '10.0.0.2'}, {'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/2', 'address': '10.0.0.9'}, {'netmask': '255.255.255.0', 'ospf': 'yes', 'name': 'Loopback0', 'address': '2.2.2.2'}], 'name': 'rtr-B', 'mgmt_ip': '192.168.0.78', 'mgmt_user': 'admin'})<br />
changed: [localhost] =&gt; (item={'mgmt_pass': 'parola', 'int': [{'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/1', 'address': '10.0.0.6'}, {'netmask': '255.255.255.252', 'ospf': 'yes', 'name': 'GigabitEthernet0/2', 'address': '10.0.0.10'}, {'netmask': '255.255.255.0', 'ospf': 'no', 'name': 'Loopback0', 'address': '3.3.3.3'}], 'name': 'rtr-C', 'mgmt_ip': '192.168.0.79', 'mgmt_user': 'admin'})</p>
<p>PLAY RECAP ********************************************************************<br />
localhost                  : ok=10   changed=2    unreachable=0    failed=0<br />
</p>
<p>This is how one of routers configuration files looks like:</p>
<p><code lang="bash[notools]"><br />
marius@net-master:/etc/ansible&gt;&gt;&gt; cat /var/www/html/rtr-A.config<br />
interface GigabitEthernet0/1<br />
no shutdown<br />
ip address 10.0.0.1 255.255.255.252<br />
interface GigabitEthernet0/2<br />
no shutdown<br />
ip address 10.0.0.5 255.255.255.252<br />
interface Loopback0<br />
no shutdown<br />
ip address 1.1.1.1 255.255.255.0
<p>router ospf 1<br />
network 10.0.0.1 0.0.0.0 area 0<br />
network 10.0.0.5 0.0.0.0 area 0<br />
network 1.1.1.1 0.0.0.0 area 0<br />
</p>
<p>So now we have the lab up and running. Why bother automating this? In the end it's a basic test environment. Here's my motivation:</p>
<p>1. I hate doing repetitive stuff<br />
2. Reproducibility. Manual repetitive stuff results in errored configurations, at least for me. If I do such a setup manually I usually get a terminal started for each of the routers and start writing commands. My problem is that almost all the time I end up messing up something like setting the wrong IP addresses on interfaces. By running this playbook I will always get the same result.<br />
3. I have the complete picture in one place and I can check the whole setup before running it, no need to switch through terminals, screens or other stuff.<br />
4. Time. I'm running this setup on Openstack by using Cisco vIOS images so getting everything up and running from scratch takes me less than 5 minutes which is pretty awesome.</p>
<p>Let me know if you have any questions and I'll be more than happy to answer. </p>
<p>Thanks</p>


</code></p></code></p></code></p></code></p></code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//uncategorized/linux/routing/ios/python/2015/02/24/ospf-lab-provisioning-on-ios-with-ansible/" title="OSPF lab provisioning on IOS with Ansible">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//linux/switching/routing/virtualization/ios/python/2014/10/12/sdn-intro-basic-l2-connectivity-by-using-ovs-and-pox/">
			        SDN Intro: Basic L2 connectivity by using OVS and POX
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            linux, switching, routing, virtualization, ios, and python
            </span> |
            
            <span class="post-date">
            Oct 12, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>You've all probably heard about this fancy SDN term that's been passing around in the networking world in the recent years. I'll try to explain below what SDN means for me and what are the benefits of using such a model. </p>
<p>SDN or Software Defined Networking refers to decoupling the data plane from the control plane. The data plane is the process by which the packets are forwarded and it's done by the hardware silicon. The control plane is the process that instructs the data plane how to behave (routing protocols, firewall policies, etc). In a typical networking device we find those 2 planes coupled in a single box. The SDN model says we can separate them and keep the packet forwarding on a box that's got the fast hardware silicon and move the control plane on a general purpose computer. Since the 2 planes are separated they need a means of communication which is OpenFlow. </p>
<p>OpenFlow is a communications protocol that allows remote manipulation of the devices forwarding tables. Think of this protocol like a standard API that you can consume by running any software. This is great because you can purchase the networking device from a specific vendor and run the controller by your own code, open source project or other proprietary software. In my opinion this provides you the freedom to choose and will push the vendors to create better and better software. Personally I'm a big fan of opensource software and I'm dreaming about the moment when the networking world will be able to get the benefits of a big opensource project. </p>
<p>Another advantage that SDN brings is a central point that controls the network. Think about how we currently manage the networking devices. Even if the network is a whole that provides services to upper applications, we currently log into each separate device and write some commands that configure services. SDN would save us from doing repetitive and boring tasks such as provisioning vlans.</p>
<p>Enough with the talk, let's start a simple scenario by using the remote-lab.net environment. The lab topology consists of two hosts connected to an OpenvSwitch switch. The OVS switch is connected to an OpenFlow controller running Pox. The controller runs the code that enables L2 connectivity between the hosts but the actual forwarding is done by the OVS switch.</p>
<p><a href="https://remote-lab.net/wp-content/uploads/2014/10/sdn_lab.png"><img src="https://remote-lab.net/wp-content/uploads/2014/10/sdn_lab.png" alt="sdn_lab" width="686" height="364" class="aligncenter size-full wp-image-284" /></a></p>
<p>Let's first enable the ports the hosts are connected to, set an openvswitch bridge where the hosts are connected, set the IP addreses on the hosts and check we have connectivity between the hosts. By default the L2 learning mechanism is done by the OpenvSwitch internals. </p>
<p><code lang="bash[notools]">root@ovs01:~&gt;&gt;&gt; ip link set dev eth1 up<br />
root@ovs01:~&gt;&gt;&gt; ip link set dev eth2 up<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-br sw0<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-port sw0 eth1<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-port sw0 eth2
<p>root@host01:~&gt;&gt;&gt; ip l set dev eth1 up<br />
root@host01:~&gt;&gt;&gt; ip addr add 192.168.0.1/24 dev eth1<br />
root@host01:~&gt;&gt;&gt; ip a s dev eth1<br />
3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000<br />
    link/ether 52:54:00:56:e2:b2 brd ff:ff:ff:ff:ff:ff<br />
    inet 192.168.0.1/24 scope global eth1<br />
    inet6 fe80::5054:ff:fe56:e2b2/64 scope link<br />
       valid_lft forever preferred_lft forever</p>
<p>root@host02:~&gt;&gt;&gt; ip l set dev eth1 up<br />
root@host02:~&gt;&gt;&gt; ip addr add 192.168.0.2/24 dev eth1<br />
root@host02:~&gt;&gt;&gt; ip a s dev eth1<br />
3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000<br />
    link/ether 52:54:00:6e:22:0b brd ff:ff:ff:ff:ff:ff<br />
    inet 192.168.0.2/24 scope global eth1<br />
    inet6 fe80::5054:ff:fe6e:220b/64 scope link<br />
       valid_lft forever preferred_lft forever</p>
<p>root@host02:~&gt;&gt;&gt; ping 192.168.0.1 -c1<br />
PING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.<br />
64 bytes from 192.168.0.1: icmp_req=1 ttl=64 time=0.946 ms</p>
<p>--- 192.168.0.1 ping statistics ---<br />
1 packets transmitted, 1 received, 0% packet loss, time 0ms<br />
rtt min/avg/max/mdev = 0.946/0.946/0.946/0.000 ms</p>
<p>Now let's go to the controller:</p>
<p><code lang="bash[notools]">root@ctrl01:~&gt;&gt;&gt; ls<br />
floodlight  pox</code></p>
<p>We see here that we have two directories that contain OpenFlow controller code - Floodlight and Pox. We'll choose Pox for our example. Pox is platform for the rapid development and prototyping of network control software using Python. Pox comes with some preinstalled components. One of the components is called forwarding.l2_learning and it does what its name says - make OpenFlow switches act as a type of L2 learning switch. You can find the code in the pox/forwarding/l2_learning.py file. We'll use this component for our example. Let's start it:</p>
<p><code lang="bash[notools]">root@ctrl01:~/pox&gt;&gt;&gt; ./pox.py --verbose forwarding.l2_learning<br />
POX 0.2.0 (carp) / Copyright 2011-2013 James McCauley, et al.<br />
DEBUG:core:POX 0.2.0 (carp) going up...<br />
DEBUG:core:Running on CPython (2.7.3/Jan 2 2013 13:56:14)<br />
DEBUG:core:Platform is Linux-3.2.0-4-amd64-x86_64-with-debian-7.4<br />
INFO:core:POX 0.2.0 (carp) is up.<br />
DEBUG:openflow.of_01:Listening on 0.0.0.0:6633</code></p>
<p>The next step is to configure OpenvSwitch to use the POX controller. OpenvSwitch has 2 ways of working with an OpenFlow controller - standalone and secure. In standalone mode, if the connection to the controller fails then it will fall back to using its internal logic to install the flows. While in secure mode it will not install any flows if the connection to the controller fails. We'll use the standalone mode with 172.16.18.6 being the IP address of the POX controller.</p>
<p><code lang="bash[notools]">root@ovs01:~&gt;&gt;&gt; ovs-vsctl set-fail-mode sw0 standalone<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl set-controller sw0 tcp:172.16.18.6:6633<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl show<br />
653dfcd6-85a4-4f72-995f-9fa05b5203f9<br />
    Bridge "sw0"<br />
        Controller "tcp:172.16.18.6:6633"<br />
            is_connected: true<br />
        fail_mode: standalone<br />
        Port "sw0"<br />
            Interface "sw0"<br />
                type: internal<br />
        Port "eth2"<br />
            Interface "eth2"<br />
        Port "eth1"<br />
            Interface "eth1"<br />
    ovs_version: "1.9.3"</code></p>
<p>We can see the following message on the OpenFlow controller:</p>
<p><code lang="bash[notools]">INFO:openflow.of_01:[46-3e-63-ba-e5-46 1] connected<br />
DEBUG:forwarding.l2_learning:Connection [46-3e-63-ba-e5-46 1]</code></p>
<p>Let's see what happens when we try to ping one host from the other:</p>
<p><code lang="bash[notools]">DEBUG:forwarding.l2_learning:installing flow for 52:54:00:6e:22:0b.2 -&gt; 52:54:00:56:e2:b2.1<br />
DEBUG:forwarding.l2_learning:installing flow for 52:54:00:56:e2:b2.1 -&gt; 52:54:00:6e:22:0b.2</code></p>
<p>Check the flows that are installed in the switch. Notice how the flows are defined:</p>
<p><code lang="bash[notools]">root@ovs01:~&gt;&gt;&gt; ovs-ofctl dump-flows sw0<br />
NXST_FLOW reply (xid=0x4):<br />
 cookie=0x0, duration=7.348s, table=0, n_packets=7, n_bytes=686, idle_timeout=10, hard_timeout=30, idle_age=1, priority=65535,icmp,in_port=2,vlan_tci=0x0000,dl_src=52:54:00:6e:22:0b,dl_dst=52:54:00:56:e2:b2,nw_src=192.168.0.2,nw_dst=192.168.0.1,nw_tos=0,icmp_type=0,icmp_code=0 actions=output:1<br />
 cookie=0x0, duration=6.329s, table=0, n_packets=6, n_bytes=588, idle_timeout=10, hard_timeout=30, idle_age=1, priority=65535,icmp,in_port=1,vlan_tci=0x0000,dl_src=52:54:00:56:e2:b2,dl_dst=52:54:00:6e:22:0b,nw_src=192.168.0.1,nw_dst=192.168.0.2,nw_tos=0,icmp_type=8,icmp_code=0 actions=output:2</code></p>
<p>You can take any of these headers and manipulate them as you wish. I believe the whole model provides great flexibility and freedom and it will lead to better networking software. </p>


</code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//linux/switching/routing/virtualization/ios/python/2014/10/12/sdn-intro-basic-l2-connectivity-by-using-ovs-and-pox/" title="SDN Intro: Basic L2 connectivity by using OVS and POX">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//linux/virtualization/2014/09/14/ansible-playbook-postfix-with-mandrill-relay/">
			        Ansible playbook: postfix with Mandrill relay
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            linux and virtualization
            </span> |
            
            <span class="post-date">
            Sep 14, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>In this post I will show how you can use Ansible to automatically install postfix mail server and configure it to relay through Mandrill. Mandrill is a transactional email platform that allows you to send up to 12.000 emails for free. I use it for my servers to avoid situations where the IP addresses assigned by my ISP are blacklisted on some RBL lists. </p>
<p>Ansible is a config manamegement software that runs agentless over SSH. You only need python installed on the remote nodes. Ansible's configuration files are called playbooks. Playbooks are written as YAML files and they are used to manage configurations of and deployments to remote machines.</p>
<p>Below is the playbook that I use to install postfix, add the required configuration to use Mandrill and reload the service in order to use the new configuration. I will explain the playbook below:</p>
<p><code lang="bash[notools]"><br />
---<br />
- hosts: basenodes<br />
  tasks:<br />
    - name: Installs postfix mail server<br />
      apt: pkg=postfix state=installed update_cache=true<br />
      notify:<br />
        - start postfix<br />
    - name: Upload mandril authentication info<br />
      copy: src=/opt/files/postfix/mandril_passwd dest=/etc/postfix/mandril_passwd mode=0600<br />
      register: mandril<br />
      notify:<br />
        - postmap mandril_passwd<br />
    - name: Append mandril relay config<br />
      lineinfile:<br />
        dest=/etc/postfix/main.cf<br />
        line=""<br />
      with_items:<br />
        - { line: 'smtp_sasl_auth_enable = yes' }<br />
        - { line: 'smtp_sasl_password_maps = hash:/etc/postfix/mandril_passwd' }<br />
        - { line: 'smtp_sasl_security_options = noanonymous' }<br />
        - { line: 'smtp_use_tls = yes' }<br />
        - { line: 'relayhost = [smtp.mandrillapp.com]' }<br />
      notify:<br />
        - restart postfix
<p>  handlers:<br />
    - name: start postfix<br />
      service: name=postfix state=started<br />
    - name: postmap mandril_passwd<br />
      command: postmap /etc/postfix/mandril_passwd<br />
      when: mandril|success<br />
    - name: restart postfix<br />
      service: name=postfix state=restarted<br />
</p>
<p>The hosts line contains the hosts group that this playbook will be applied to.<br />
Each play contains a list of tasks, which are actually calls to Ansible modules. We see that the first task is called 'Installs postfix mail server' and it uses the apt module to get the postfix package in the installed stated. update_cache=true ensures that 'apt-get update' will be run before installing the postfix package. The notify section contains the handlers. Handlers are lists of tasks, not really any different from regular tasks, that are referenced by name. You can find them in the handlers sections. Looking at our example - the 'start postfix' handler ensures that the postfix server is started. </p>
<p>The 'Upload mandril authentication info' task copies the /opt/files/postfix/mandril_passwd file on the ansible server to the remote node with /etc/postfix/mandril_passwd as a destination location. The mandril_passwd file contains the authentication details for the Mandril platform. The mode key contains the permissions the destination file will have. The register line gets the result of the copy operation stored in the mandril variable. After getting the file copied we need to create the postfix lookup table based on that file. In order to do this we run the 'postmap mandril_passwd' handler which runs the 'postmap /etc/postfix/mandril_passwd' command only if the copy task was run successfully.</p>
<p>The 'Append mandril relay config' task will add the config lines to the postfix main.cf files. We'll store the lines in a dictionary. A dictionary is represented in a simple key: and value form:. Each new line will be the value stored in the 'line' key of each dictionary element. After adding the lines to main.cf we'll restart postfix by running the 'restart postfix' handler. </p>
<p>You may find below the output of running the playbook : </p>
<p><code lang="bash[notools]"><br />
root@ansible:/etc/ansible/playbooks&gt;&gt;&gt; ansible-playbook /etc/ansible/playbooks/playbook.yml
<p>PLAY [basenodes] ************************************************************** </p>
<p>GATHERING FACTS *************************************************************** </p>
<p>TASK: [Installs postfix mail server] ******************************************<br />
changed: [node01.remote-lab.net]</p>
<p>TASK: [Upload mandril authentication info] ************************************<br />
changed: [node01.remote-lab.net]</p>
<p>TASK: [Append mandril relay config] *******************************************<br />
changed: [node01.remote-lab.net] =&gt; (item={'line': 'smtp_sasl_auth_enable = yes'})<br />
changed: [node01.remote-lab.net] =&gt; (item={'line': 'smtp_sasl_password_maps = hash:/etc/postfix/mandril_passwd'})<br />
changed: [node01.remote-lab.net] =&gt; (item={'line': 'smtp_sasl_security_options = noanonymous'})<br />
changed: [node01.remote-lab.net] =&gt; (item={'line': 'smtp_use_tls = yes'})<br />
changed: [node01.remote-lab.net] =&gt; (item={'line': 'relayhost = [smtp.mandrillapp.com]'})</p>
<p>NOTIFIED: [start postfix] *****************************************************<br />
ok: [node01.remote-lab.net]</p>
<p>NOTIFIED: [postmap mandril_passwd] ********************************************<br />
changed: [node01.remote-lab.net]</p>
<p>NOTIFIED: [restart postfix] ***************************************************<br />
changed: [node01.remote-lab.net]</p>
<p>PLAY RECAP ********************************************************************<br />
node01.remote-lab.net      : ok=7    changed=5    unreachable=0    failed=0<br />
</p>


</code></p></code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//linux/virtualization/2014/09/14/ansible-playbook-postfix-with-mandrill-relay/" title="Ansible playbook: postfix with Mandrill relay">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//sample-post">
			        Sample post from harmony
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            blog
            </span> |
            
            <span class="post-date">
            Aug 19, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>Just a sample post to show some of the <em>typography</em> elements supported from 
<strong>harmony</strong> theme.</p>

	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//sample-post" title="Sample post from harmony">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//blog/jekyll/2014/07/28/welcome-to-jekyll/">
			        What is Jekyll!
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            blog and jekyll
            </span> |
            
            <span class="post-date">
            Jul 28, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p><a href="http://jekyllrb.com">Jekyll</a> is a static site generator, an open-source tool for creating simple yet powerful websites of all shapes and sizes. Here is a little quote from the official website:</p>

	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//blog/jekyll/2014/07/28/welcome-to-jekyll/" title="What is Jekyll!">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//linux/switching/routing/ios/2014/05/21/lab-basic-ospf-routing-scenario/">
			        Lab - basic OSPF routing scenario
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            linux, switching, routing, and ios
            </span> |
            
            <span class="post-date">
            May 21, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>Hello guys,</p>
<p>In the following post we'll see how we can do a basic routing scenario by using the remote-lab.net virtual appliances. Below is the logical diagram of the scenario. Our objective is to esatblish connectivity between the 2 clients: host01 - 10.0.0.10 and host02 - 10.0.1.10. Each of the hosts will be connected to a router that  will be the first hop router for the hosts subnet. The 2 routers will be connected by 2 redundant links. We'll set up OSPF as a routing protocol between the 2 routers that will be used to advertise the clients subnets. </p>
<p>rtr01 is an Arista vEOS and rtr02 is running Vyatta core. host01 and host02 are running Debian.</p>
<p><a href="https://remote-lab.net/wp-content/uploads/2014/05/routing-lab-New-Page.png"><img src="https://remote-lab.net/wp-content/uploads/2014/05/routing-lab-New-Page.png" alt="ospf routing lab logical" width="821" height="729" class="aligncenter size-full wp-image-260" /></a></p>
<p>Now let's get to the physical setup (which is actually virtual as all the components are VMs ). Each system (clients and routers) will be connected to the layer 2 switch (openvswitch running on Linux). We'll need to set up the links that connect the routers to the switch as trunks in order to allow multiple vlans to get through. The ports that connect the clients to the switch will be set as access ports. Please note that in a real world scenario you'll need to connect the routers by 2 different physical links across separate geographical paths to ensure rendundancy. Below is the physical diagram of the setup.</p>
<p><a href="https://remote-lab.net/wp-content/uploads/2014/05/routing-physical-New-Page.png"><img src="https://remote-lab.net/wp-content/uploads/2014/05/routing-physical-New-Page.png" alt="routing lab physical" width="745" height="625" class="aligncenter size-full wp-image-259" /></a></p>
<p>First thing we need to do is to configure the openvswitch. We'll create a bridge that contains all the ports and set up the client ports in access mode. By default all the openvswitch ports are trunks.</p>
<p><code lang="bash[notools]">lab@console01:~&gt;&gt;&gt; ovs01<br />
root@ovs01:~&gt;&gt;&gt; for i in {1..4}; do ip l set dev eth$i up;done<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-br l2switch<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-port l2switch eth1 tag=10<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-port l2switch eth2 tag=20<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-port l2switch eth3<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl add-port l2switch eth4<br />
root@ovs01:~&gt;&gt;&gt; ovs-vsctl show<br />
653dfcd6-85a4-4f72-995f-9fa05b5203f9<br />
    Bridge "l2switch"<br />
        Port "l2switch"<br />
            Interface "l2switch"<br />
                type: internal<br />
        Port "eth3"<br />
            Interface "eth3"<br />
        Port "eth2"<br />
            tag: 20<br />
            Interface "eth2"<br />
        Port "eth4"<br />
            Interface "eth4"<br />
        Port "eth1"<br />
            tag: 10<br />
            Interface "eth1"<br />
    ovs_version: "1.9.3"</code>       </p>
<p>Set up the client interfaces IP addresses and default routes:</p>
<p><code lang="bash[notools]">lab@console01:~&gt;&gt;&gt; host01<br />
root@host01:~&gt;&gt;&gt; ip l set dev eth1 up<br />
root@host01:~&gt;&gt;&gt; ip addr add 10.0.0.10/24 dev eth1<br />
root@host01:~&gt;&gt;&gt; ip route add default via 10.0.0.1
<p>lab@console01:~&gt;&gt;&gt; host02<br />
root@host02:~&gt;&gt;&gt; ip l set dev eth1 up<br />
root@host02:~&gt;&gt;&gt; ip addr add 10.0.1.10/24 dev eth1<br />
root@host01:~&gt;&gt;&gt; ip route add default via 10.0.1.1        </p>
<p>Configure the vlans and SVI IP addresses on the routers:</p>
<p><code lang="c[notools]">lab@console01:~&gt;&gt;&gt; rtr01<br />
rtr01&gt;en<br />
rtr01#configure<br />
rtr01(config)#vlan 10<br />
rtr01(config-vlan-10)#name host01-vlan<br />
rtr01(config-vlan-10)#vlan 100<br />
rtr01(config-vlan-100)#name path1-vlan<br />
rtr01(config-vlan-100)#vlan 200<br />
rtr01(config-vlan-200)#name path2-vlan<br />
rtr01(config)#int ethernet 1<br />
rtr01(config-if-Et1)#switchport mode trunk<br />
rtr01(config-if-Et1)#switchport trunk allowed vlan 10,100,200<br />
rtr01(config-vlan-200)#int vlan 10<br />
rtr01(config-if-Vl10)#ip address 10.0.0.1/24<br />
rtr01(config-if-Et1)#int vlan 100<br />
rtr01(config-if-Vl100)#ip address 192.168.0.1/30<br />
rtr01(config-if-Vl100)#int vlan 200<br />
rtr01(config-if-Vl200)#ip address 192.168.0.5/30                                                         
<p>lab@console01:~&gt;&gt;&gt; rtr02<br />
admin@rtr02:~&gt;&gt;&gt; configure<br />
[edit]<br />
admin@rtr02# set interfaces ethernet eth1 vif 20 address 10.0.1.1/24<br />
[edit]<br />
admin@rtr02# set interfaces ethernet eth1 vif 100 address 192.168.0.2/30<br />
[edit]<br />
admin@rtr02# set interfaces ethernet eth1 vif 200 address 192.168.0.6/30<br />
admin@rtr02# commit<br />
[edit]<br />
admin@rtr02# save<br />
Saving configuration to '/config/config.boot'...<br />
Done</p>
<p>Let's do some connectivity tests:</p>
<p><code lang="bash[notools]">rtr01&gt;ping 10.0.0.10<br />
PING 10.0.0.10 (10.0.0.10) 72(100) bytes of data.<br />
80 bytes from 10.0.0.10: icmp_req=1 ttl=64 time=12.9 ms    
<p>rtr01&gt;ping 192.168.0.2<br />
PING 192.168.0.2 (192.168.0.2) 72(100) bytes of data.<br />
80 bytes from 192.168.0.2: icmp_req=1 ttl=64 time=16.7 ms                </p>
<p>rtr01&gt;ping 192.168.0.6<br />
PING 192.168.0.6 (192.168.0.6) 72(100) bytes of data.<br />
80 bytes from 192.168.0.6: icmp_req=1 ttl=64 time=13.2 ms       </p>
<p>admin@rtr02:~&gt;&gt;&gt; ping 10.0.1.10<br />
PING 10.0.1.10 (10.0.1.10) 56(84) bytes of data.<br />
64 bytes from 10.0.1.10: icmp_req=1 ttl=64 time=3.74 ms         </p>
<p>Now that we have the connectivity established on the connected links let's move forward and set up OSPF :</p>
<p><code lang="c[notools]">lab@console01:~&gt;&gt;&gt; rtr01<br />
rtr01&gt;en<br />
rtr01#configure<br />
rtr01(config)#ip routing<br />
rtr01(config)#router ospf 10<br />
rtr01(config-router-ospf)#network 10.0.0.1 0.0.0.0 area 0<br />
rtr01(config-router-ospf)#network 192.168.0.1 0.0.0.0 area 0<br />
rtr01(config-router-ospf)#network 192.168.0.5 0.0.0.0 area 0 
<p>lab@console01:~&gt;&gt;&gt; rtr02<br />
admin@rtr02:~&gt;&gt;&gt; configure<br />
[edit]<br />
admin@rtr02#<br />
admin@rtr02# set protocols ospf area 0 network 10.0.1.0/24<br />
[edit]<br />
admin@rtr02# set protocols ospf area 0 network 192.168.0.0/30<br />
[edit]<br />
admin@rtr02# set protocols ospf area 0 network 192.168.0.4/30<br />
admin@rtr02# commit</p>
<p>Once that we have the ospf configuration done we can proceed and check the OSPF neighbor status on the 2 routers. We'll see that we have 2 equal cost paths to the hosts subnets. This means that the routers will load balance the packets through the 2 links.      </p>
<p><code lang="c[notools]">rtr01#show ip ospf neighbor<br />
Neighbor ID     VRF    Pri   State            Dead Time   Address         Interface<br />
172.16.18.5     default    1   FULL/BDR         00:00:31    192.168.0.6     Vlan200<br />
172.16.18.5     default    1   FULL/DR          00:00:31    192.168.0.2     Vlan100    
<p>rtr01#show ip route 10.0.1.0/24<br />
Codes: C - connected, S - static, K - kernel,<br />
       O - OSPF, IA - OSPF inter area, E1 - OSPF external type 1,<br />
       E2 - OSPF external type 2, N1 - OSPF NSSA external type 1,<br />
       N2 - OSPF NSSA external type2, B I - iBGP, B E - eBGP,<br />
       R - RIP, I - ISIS, A B - BGP Aggregate, A O - OSPF Summary                                                                                                                             </p>
<p> O      10.0.1.0/24 [110/20] via 192.168.0.2, Vlan100<br />
                             via 192.168.0.6, Vlan200                     </p>
<p>admin@rtr02:~&gt;&gt;&gt; show ip ospf neighbor </p>
<p>    Neighbor ID Pri State           Dead Time Address         Interface            RXmtL RqstL DBsmL<br />
192.168.0.5       1 Full/Backup       36.750s 192.168.0.1     eth1.100:192.168.0.2     0     0     0<br />
192.168.0.5       1 Full/DR           36.960s 192.168.0.5     eth1.200:192.168.0.6     0     0     0 </p>
<p>admin@rtr02:~&gt;&gt;&gt; show ip route 10.0.0.0/24<br />
Routing entry for 10.0.0.0/24<br />
  Known via "ospf", distance 110, metric 20, best<br />
  Last update 00:04:42 ago<br />
  * 192.168.0.1, via eth1.100<br />
  * 192.168.0.5, via eth1.200                 </p>
<p>What if we want to set one of the links as primary ? We need to set a higher cost for the secondary link. At this time both of the paths have a cost of 20 (10 for the network segment that connects the 2 routers + 10 for the host network segment). Let'schoose the vlan 200 as secondary and increase the cost for the secondary link to 11.</p>
<p><code lang="c[notools]">rtr01#configure<br />
rtr01(config)#int vlan 200<br />
rtr01(config-if-Vl200)#ip ospf cost 11<br />
rtr01(config-if-Vl200)#show ip route 10.0.1.0/24<br />
Codes: C - connected, S - static, K - kernel,<br />
       O - OSPF, IA - OSPF inter area, E1 - OSPF external type 1,<br />
       E2 - OSPF external type 2, N1 - OSPF NSSA external type 1,<br />
       N2 - OSPF NSSA external type2, B I - iBGP, B E - eBGP,<br />
       R - RIP, I - ISIS, A B - BGP Aggregate, A O - OSPF Summary                                                                                                                             
<p> O      10.0.1.0/24 [110/20] via 192.168.0.2, Vlan100      </p>
<p>We can see that the routing table only contains the vlan 100 path. What happens if vlan 100 goes down ? </p>
<p><code lang="c[notools]">rtr01(config)#int vlan 100<br />
rtr01(config-if-Vl100)#shut<br />
rtr01(config-if-Vl100)#show ip route 10.0.1.0/24<br />
Codes: C - connected, S - static, K - kernel,<br />
       O - OSPF, IA - OSPF inter area, E1 - OSPF external type 1,<br />
       E2 - OSPF external type 2, N1 - OSPF NSSA external type 1,<br />
       N2 - OSPF NSSA external type2, B I - iBGP, B E - eBGP,<br />
       R - RIP, I - ISIS, A B - BGP Aggregate, A O - OSPF Summary                                                                                                                             
<p> O      10.0.1.0/24 [110/21] via 192.168.0.6, Vlan200          </p>
<p>We can see that the vlan 200 path is installed in the routing table with a cost of 21 ( 11 + 10).</p>
<p>I hope this post is useful for getting an idea of how you can use the virtual lab. Please let me know if you any questions.                                                             </p>


</code></p></code></p></code></p></code></p></code></p></code></p></code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//linux/switching/routing/ios/2014/05/21/lab-basic-ospf-routing-scenario/" title="Lab - basic OSPF routing scenario">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//linux/virtualization/storage/2014/05/07/virtualized-application-infrastructure/">
			        Virtualized application infrastructure
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            linux, virtualization, and storage
            </span> |
            
            <span class="post-date">
            May 7, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>In this post I'll show how you can build a secure virtualized infrastructure for a basic webapp. We will break the setup into VMs that provide isolated services. You can find below the infrastructure diagram. The followings steps will show how you can set up a bare-metal server running Debian Wheezy to act as a KVM hypervisor and the process of deploying and configuring the VMs and the services they are running. </p>
<p><a href="https://remote-lab.net/wp-content/uploads/2014/05/rlug-New-Page.png"><img src="https://remote-lab.net/wp-content/uploads/2014/05/rlug-New-Page.png" alt="rlug - New Page" width="832" height="814" class="aligncenter size-full wp-image-255" /></a></p>
<p>Install kvm and tools:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; aptitude install qemu-kvm libvirt-bin virt-manager virt-viewer</code></p>
<p>Install openvswitch :</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; aptitude install openvswitch-switch openvswitch-datapath-source</code></p>
<p>Build Open vSwitch datapath kernel module:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; module-assistant auto-install openvswitch-datapath</code></p>
<p>The management IP address of the hypervisor and the other public IP addresses are assigned on the same interface by the hosting provider. In order to provide Internet connectivity for the VMs we need to create a bridge containing the physical interface where the public IPs are routed and add the VMs ports to this bridge. The trouble is that since this is also the management link we'll lose connectivity after adding the physical interface to the bridge. After this operation we need to assign the management IP address to the bridge interface. For doing this we edit the /etc/network/interfaces file.</p>
<p>Add openvswitch bridges:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; ovs-vsctl add-br sw-net</code></p>
<p>Edit the /etc/network/interfaces file:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; cat /etc/network/interfaces<br />
auto sw-net<br />
iface sw-net inet static<br />
  address   46.4.71.66<br />
  broadcast 46.4.71.95<br />
  netmask   255.255.255.224<br />
  gateway   46.4.71.65<br />
pre-up ip link set dev eth0 up</code></p>
<p>At boot time the openvswitch daemon is started after the network init script so when the network init script is run it won't find the sw-net interface defined in /etc/network/interfaces file. A dirty workaround for this is to re-run the network init script after all the services are loaded. In order to do this we need to edit the /etc/rc.local file:  </p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; cat /etc/rc.local<br />
/etc/init.d/networking restart<br />
exit 0 </code></p>
<p>Now let's add the physical interface to the bridge. After this we should either restart the network service from the console or do a hard reset:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; ovs-vsctl add-port sw-net eth0</code></p>
<p>The next step is to add the second bridge, where the internal network ports will be connected </p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; ovs-vsctl add-br sw-lan</code></p>
<p>I prefer using virt-install for new VMs provisioning. The problem with it is that it currently doesn't support Open vSwitch bridges so we'll need to adjust it a little by adding the following line to the /usr/lib/pymodules/python2.7/virtinst/VirtualNetworkInterface.py file. This will add the virtualport tag to the VM xml definition:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; diff -u /usr/lib/pymodules/python2.7/virtinst/VirtualNetworkInterface.py /usr/lib/pymodules/python2.7/virtinst/VirtualNetworkInterface.py.orig<br />
--- /usr/lib/pymodules/python2.7/virtinst/VirtualNetworkInterface.py	2014-05-06 22:06:21.396072330 +0200<br />
+++ /usr/lib/pymodules/python2.7/virtinst/VirtualNetworkInterface.py.orig	2014-05-06 22:13:17.121958858 +0200<br />
@@ -384,7 +384,6 @@<br />
         xml += "      <mac address="%s" />\n" % self.macaddr<br />
         xml += target_xml<br />
         xml += model_xml<br />
-        xml += "      <virtualport type="openvswitch" />\n"<br />
         xml += "    "<br />
         return xml</code></p>
<p>Now that we have the networking ready the last thing that we need are the storage files that the VMs will use. For creating the files we use the qemu-img utility. I prefer qcow2 files as they provide thin provision and snapshot capabilities. /var/lib/libvirt/images is the default directory used by libvirt-bin so let's create the storage files here:</p>
<p><code lang="bash[notools]">root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; qemu-img create -f qcow2 rtr01.qcow2 10G<br />
Formatting 'rtr01.qcow2', fmt=qcow2 size=10737418240 encryption=off cluster_size=65536 </code></p>
<p>We can now create the VM and start the OS installation. We'll first install the rtr01 VM as it will provide Internet connectivity for the rest of the VMs in the internal network. The following command will generate a VM called rtr01 with 4 vCPUs, 4GB of ram, storage file located at /var/lib/libvirt/images/rtr01.qcow2 and 2 network interfaces - one in the bridge connected to the Internet and another connected to the internal network, the console is presented over VNC and it will first boot from the cdrom device loaded from the /var/lib/libvirt/images/vyatta-livecd_VC6.6R1_amd64.iso file. The disk and network interface will use paravirtualized drivers to obtain increased I/O performance.</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; virt-install --name rtr01 --vcpus=4 --ram=4096 --disk path=/var/lib/libvirt/images/rtr01.qcow2,bus=virtio --network bridge=sw-net,model=virtio --network bridge=sw-lan,model=virtio --graphics vnc --cdrom /var/lib/libvirt/images/vyatta-livecd_VC6.6R1_amd64.iso --boot cdrom</code></p>
<p>After this command is issued a console windows will pop up and it will prompt the cdrom installation. After finishing the installation we can proceed to configuring the device:</p>
<p><code lang="bash[notools]"><br />
# set interfaces IP addresses<br />
set interfaces ethernet eth0 mac 00:50:56:00:5e:97<br />
set interfaces ethernet eth0 address 46.4.71.77/27<br />
set protocols static route 0.0.0.0/0 next-hop 46.4.71.65<br />
set system host-name rtr01<br />
set system domain-name nullzero.me<br />
set interfaces ethernet eth1 10.0.1.1/24<br />
set interfaces ethernet eth1 address 10.0.1.1/24
<p># set SNAT for internal network<br />
set nat source rule 10 source address 10.0.1.0/24<br />
set nat source rule 10 outbound-interface eth0<br />
set nat source rule 10 translation address masquerade</p>
<p># set DNAT for the request coming on port tcp 80 on the public IP<br />
set nat destination rule 10 destination address 46.4.71.77<br />
set nat destination rule 10 inbound-interface eth0<br />
set nat destination rule 10 destination port 80<br />
set nat destination rule 10 translation address 10.0.1.2<br />
set nat destination rule 10 translation port 80<br />
set nat destination rule 10 protocol tcp</p>
<p># generate server and client certificates and keys<br />
vyatta@rtr01:~$ sudo -s<br />
vbash-4.1# cp -R /usr/share/doc/openvpn/examples/easy-rsa/2.0/* /etc/openvpn/<br />
edit KEY_COUNTRY, KEY_PROVINCE, KEY_CITY, KEY_ORG, KEY_EMAIL variables<br />
vbash-4.1# vi /etc/openvpn/vars<br />
vbash-4.1# cd /etc/openvpn<br />
vbash-4.1# source vars<br />
vbash-4.1# ./clean-all<br />
vbash-4.1# ./build-ca<br />
vbash-4.1# ./build-dh<br />
vbash-4.1# ./build-key-server rtr01<br />
vbash-4.1# ./build-key client<br />
vbash-4.1# mkdir /config/auth<br />
vbash-4.1# cp -R /etc/openvpn/keys/* /config/auth</p>
<p># configure the server certificates and key location<br />
set interfaces openvpn vtun0 tls ca-cert-file /config/auth/ca.crt<br />
set interfaces openvpn vtun0 tls cert-file /config/auth/rtr01.crt<br />
set interfaces openvpn vtun0 tls dh-file /config/auth/dh1024.pem<br />
set interfaces openvpn vtun0 tls key-file /config/auth/rtr01.key</p>
<p># configure the openvpn server<br />
set interfaces openvpn vtun0 mode server<br />
set interfaces openvpn vtun0 server subnet 172.16.17.0/24<br />
set interfaces openvpn vtun0 server push-route 10.0.1.0/24<br />
set interfaces openvpn vtun0 openvpn-option "--comp-lzo --mssfix --tun-mtu 1488"</p>
<p># openvpn client config file</p>
<p>marius@remoteur:~&gt;&gt;&gt; cat /etc/openvpn/nullzero.conf<br />
client<br />
dev tun<br />
proto udp<br />
remote 46.4.71.77 1194<br />
resolv-retry infinite<br />
nobind<br />
persist-key<br />
persist-tun<br />
ca /etc/openvpn/nullzero/ca.crt<br />
cert /etc/openvpn/nullzero/client.crt<br />
key /etc/openvpn/nullzero/client.key<br />
ns-cert-type server<br />
comp-lzo<br />
verb 3</p>
<p>#configure firewall<br />
set firewall state-policy established action 'accept'<br />
set firewall state-policy related action 'accept'<br />
set firewall all-ping 'enable'<br />
edit firewall name rtr01<br />
set default-action 'drop'<br />
set rule 10 action accept<br />
set rule 10 destination port 22<br />
set rule 10 protocol tcp<br />
set rule 11 action accept<br />
set rule 11 destination port 80<br />
set rule 11 protocol tcp<br />
set rule 12 action accept<br />
set rule 12 destination port 1194<br />
set rule 12 protocol udp<br />
exit<br />
set interfaces ethernet eth0 firewall in name rtr01</p>
<p>After completing these steps we should have a working router, firewall and VPN server.</p>
<p>Now let's continue with creating the second VM. We'll do a network install from minimal CD. First create the storage file:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; qemu-img create -f qcow2 /var/lib/libvirt/images/lb01.qcow2 10G<br />
Formatting '/var/lib/libvirt/images/lb01.qcow2', fmt=qcow2 size=10737418240 encryption=off cluster_size=65536</code></p>
<p>Next we can start the installation process by using the cdrom file located at /var/lib/libvirt/images/debian-7.5.0-amd64-netinst.iso </p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; virt-install --name lb01 --vcpus=2 --ram=4096 --disk path=/var/lib/libvirt/images/lb01.qcow2,bus=virtio --network bridge=sw-lan,model=virtio  --graphics vnc --cdrom /var/lib/libvirt/images/debian-7.5.0-amd64-netinst.iso --boot cdrom</code></p>
<p>After completing the OS installation we have a fresh running Debian Wheezy system. We don't want to repeat the install process for the other files so we'll just copy the existing image of the Debian system and modify the IP settings and hostnames. We first copy the base image, then attach it by using qemu-nbd, mount the partition where the file system resides and then edit the files that we need.</p>
<p><code lang="bash[notools]">root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; cp lb01.qcow2 db01.qcow2; cp lb01.qcow2 web01.qcow2<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; modprobe nbd max_part=8<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; qemu-nbd -c /dev/nbd0 web01.qcow2<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; kpartx -a /dev/nbd0<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; mount /dev/mapper/nbd0p1 /mnt<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; vim /mnt/etc/network/interfaces<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; vim /mnt/etc/hosts<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; vim /mnt/etc/hostname<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; umount /mnt<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; kpartx -d /dev/nbd0<br />
root@vmm:/var/lib/libvirt/images&gt;&gt;&gt; qemu-nbd -d /dev/nbd0</code></p>
<p>We repeat the steps above for the db01.qcow2 file.</p>
<p>Let's now create the web01 and db01 VMs. Since we already have the base storage files we don't need to run the OS installation:</p>
<p><code lang="bash[notools]">root@vmm:~&gt;&gt;&gt; virt-install --name web01 --vcpus=4 --ram=4096 --disk path=/var/lib/libvirt/images/web01.qcow2,bus=virtio --network bridge=sw-lan,model=virtio  --graphics vnc --import<br />
root@vmm:~&gt;&gt;&gt; virt-install --name db01 --vcpus=4 --ram=4096 --disk path=/var/lib/libvirt/images/db01.qcow2,bus=virtio --network bridge=sw-lan,model=virtio  --graphics vnc --import</code></p>
<p>Once we have booted al the VMs let's start configuring the services.</p>
<p>On the http load balancer we'll install varnish and configure the web server as backend: </p>
<p><code lang="bash[notools]">root@lb01:~&gt;&gt;&gt; aptitude install varnish<br />
root@lb01:~&gt;&gt;&gt; sed -i 's/6081/80/' /etc/default/varnish<br />
root@lb01:~&gt;&gt;&gt; sed -i 's/127.0.0.1/10.0.1.3/' /etc/varnish/default.vcl<br />
root@lb01:~&gt;&gt;&gt; sed -i 's/8080/80/' /etc/varnish/default.vcl<br />
root@lb01:~&gt;&gt;&gt; /etc/init.d/varnish restart</code></p>
<p>On the web server we'll install nginx and php-fpm and configure the default vhost:</p>
<p><code lang="bash[notools]">root@web01:~&gt;&gt;&gt; aptitude install nginx php5-fpm php5-mysql</code></p>
<p>Add the following location block to the first server block:</p>
<p><code lang="bash[notools]">location ~ \.php$ {<br />
        fastcgi_pass   unix:/var/run/php5-fpm.sock;<br />
        fastcgi_index  index.php;<br />
        include        fastcgi_params;<br />
}</code></p>
<p>Create an index file in the document root that will query the database server:</p>
<p><code lang="bash[notools]">root@web01:/srv/www&gt;&gt;&gt; cat index.php<br />
<?php<br />
$con=mysqli_connect("10.0.1.4","user","parola","test");</p>
<p>$result = mysqli_query($con,"SELECT * FROM testable");</p>
<p>$row = mysqli_fetch_array($result);<br />
echo $row['hello'];</p>
<p>mysqli_close($con);<br />
?></code></p>
<p>On the database server we'll install mysql server and create a dummy database and table;</p>
<p><code lang="bash[notools]">root@db01:~&gt;&gt;&gt; aptitude install mysql-server<br />
root@db01:~&gt;&gt;&gt; mysql<br />
Welcome to the MySQL monitor.  Commands end with ; or \g.<br />
Your MySQL connection id is 43<br />
Server version: 5.5.37-0+wheezy1 (Debian)
<p>Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.</p>
<p>Oracle is a registered trademark of Oracle Corporation and/or its<br />
affiliates. Other names may be trademarks of their respective<br />
owners.</p>
<p>Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.</p>
<p>mysql&gt; create database test;<br />
mysql&gt; use test;<br />
mysql&gt; CREATE TABLE testable (hello VARCHAR(20));<br />
mysql&gt; INSERT INTO testable (hello) VALUES("Hello World!");<br />
mysql&gt; CREATE USER 'user'@'10.0.1.3' IDENTIFIED BY 'parola';<br />
mysql&gt; GRANT ALL PRIVILEGES ON * . * TO 'user'@'10.0.1.3';<br />
mysql&gt; FLUSH PRIVILEGES;<br />
mysql&gt; exit</p>
<p>After this final step we have our setup ready and http://app.nullzero.me/ should show the Hello World!</p>


</code></p></code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//linux/virtualization/storage/2014/05/07/virtualized-application-infrastructure/" title="Virtualized application infrastructure">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//linux/2014/02/23/junos-interfaces-ip-addresses-a-and-ptr-records-generator/">
			        JunOS interfaces IP addresses DNS records generator
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            linux
            </span> |
            
            <span class="post-date">
            Feb 23, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>This post is closely related to the previous one where I showed how you can parse the interfaces IP addresses from a curly bracket JunOS config file. The following script will be used to generate A and PTR records for a BIND zone file. Please note that the script needs to be run within the same directory as the Perl parser script and the config file.</p>
<p>The entries will have the following format:<br />
type-fpc-pic-port 300 IN A $value<br />
$value IN PTR type-fpc-pic-port.hostname.domain</p>
<p> <code lang="bash[notools]"><br />
#/bin/bash<br />
PERL='/usr/bin/perl'<br />
PARSER='./parser.pl'<br />
CONFIG_FILE='config.txt'<br />
CONFIG_SYS='sys'<br />
CONFIG_INT='int'<br />
hostname=`$PERL $PARSER $CONFIG_SYS | grep host-name | sed -e s/host-name// -e s/\;// | tr '\r' ' ' | sed -e s/\ //g`<br />
domain=`$PERL $PARSER $CONFIG_SYS | grep domain-name | sed -e s/domain-name// -e s/\;// | tr '\r' ' ' | sed -e s/\ //g`<br />
for i in `grep "ge-[0-9]\/[0-9]\/[0-9] {\|ae[0-9] {\|lo[0-9] {" $CONFIG_FILE | sed -e s/\ //g  -e s/\{// | tr '\r' ' '`<br />
    do<br />
        intname=`echo $i | sed s/\\\//-/g`<br />
        for j in `$PERL $PARSER $CONFIG_INT $i | grep unit | sed -e s/\ unit//g  -e s/\{// -e s/\ //g | tr '\r' ' '`<br />
            do<br />
                inetaddr=`$PERL $PARSER $CONFIG_INT $i $j | tr '\r' ' '`<br />
                lastoct=`echo $inetaddr | awk -F '.' {'print $4'}`<br />
                if [ $j -eq 0 ]<br />
                then<br />
                    echo "$intname 300 IN A  $inetaddr"<br />
                    echo "$lastoct  IN  PTR $intname.$hostname.$domain."<br />
                    echo
<p>                else<br />
                    if [ $j -eq 10 ]<br />
                    then<br />
                        echo "$intname 300 IN A  $inetaddr"<br />
                        echo "$lastoct  IN  PTR $intname.$hostname.$domain."<br />
                        echo<br />
                    else<br />
                        echo "$intname-u$j 300 IN A  $inetaddr"<br />
                        echo "$lastoct  IN  PTR $intname-u$j.$hostname.$domain."<br />
                        echo<br />
                    fi<br />
                fi<br />
            done<br />
    done<br />
</p>


</code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//linux/2014/02/23/junos-interfaces-ip-addresses-a-and-ptr-records-generator/" title="JunOS interfaces IP addresses DNS records generator">
  						Read More
					</a>
  				</p>
  			</div>
  		
  			<div class="post">
    			<h3 class="post-title">
			      <a href="http://remoteur.github.io//linux/2014/02/23/junos-curly-brackets-configuration-parser/">
			        JunOS config interfaces IP address parser
			      </a>
    			</h3>

          <p class="post-meta">
            
            <span class="categories">
            linux
            </span> |
            
            <span class="post-date">
            Feb 23, 2014 
            </span>
          </p>          
    			    			
  				<p>
	  				<p>Hello guys,</p>
<p>In todays post I will show how you can obtain an interface IP address out of a JunOS curly brackets configuration file. You may find below the script and also the source configuration file. Please note that in order to run the script both files need to be placed in the same directory. </p>
<p>Please check it and let me know what you think, it's my first Perl script so it could definitely be improved.</p>
<p><code lang="perl[notools]">#!/usr/bin/perl<br />
open (CONFIG, 'config.txt');<br />
my $data = do { local $/; <config>;};<br />
close (CONFIG);
<p>my $system = $data =~ m{(\bsystem\s*({(?:(?&gt;[^{}]+)|(?-1))*}))}<br />
    ? $1<br />
    : die "system not found";</p>
<p>my $intconfig = $data =~ m{(\binterfaces\s*({(?:(?&gt;[^{}]+)|(?-1))*}))}<br />
    ? $1<br />
    : die "interfaces not found";</p>
<p>if ($ARGV[0] eq 'sys') {<br />
    print $system;<br />
}</p>
<p>if ($ARGV[0] eq 'int') {<br />
    if (!defined $ARGV[1]) {<br />
        print $intconfig, "\n";<br />
    }<br />
    if (defined $ARGV[1]) {<br />
        my $int = $intconfig =~ m{(\b$ARGV[1]\s*({(?:(?&gt;[^{}]+)|(?-1))*}))}<br />
            ? $1<br />
            : die "$ARGV[1] not found";</p>
<p>        if (!defined $ARGV[2]) {<br />
            print $int. "\n";<br />
        }</p>
<p>        if (defined $ARGV[2]) {<br />
            my $unit = $int =~m{(\bunit $ARGV[2]\s*({(?:(?&gt;[^{}]+)|(?-1))*}))}<br />
                ? $1<br />
                : die "$ARGV[2] not found";</p>
<p>            my $inet = $unit =~ m{(\bfamily inet\s*({(?:(?&gt;[^{}]+)|(?-1))*}))}<br />
                ? $1<br />
                : die "family inet not found in section";</p>
<p>            my $inetaddr = $inet =~ m{\baddress\s(\d{1,3}(?:\.\d{1,3}){3})}<br />
                ? $1<br />
                : die "no IP address";<br />
            print $inetaddr, "\n";<br />
        }<br />
    }<br />
}</p>
<p>if ($ARGV[0] eq '--help' or !defined $ARGV[0]) {<br />
    print "Usage : ./parser.pl sys                              # outputs system section config", "\n";<br />
    print "        ./parser.pl int                              # outputs interfaces section config", "\n";<br />
    print "        ./parser.pl int [int-name]                   # outputs specific interface section config", "\n";<br />
    print "        ./parser.pl int ge-1/1/7                     # outputs ge-1/1/7 interface section config", "\n";<br />
    print "        ./parser.pl int [int-name] [unit-id]         # outputs specific interface unit IP address", "\n";<br />
    print "        ./parser.pl int ge-1/1/7 1001                # outputs ge-1/1/7 interface unit 1001 IP address", "\n";<br />
}<br />
</p>
<p><code lang="perl[notools]"><br />
marius@remoteur:~&gt;&gt;&gt; cat config.txt<br />
system {<br />
    host-name junos-device;<br />
    domain-name corporate.net<br />
    time-zone Europe/Bucharest;<br />
    default-address-selection;<br />
    no-redirects;<br />
    location country-code RO;<br />
}<br />
interfaces {<br />
    ge-1/0/0 {<br />
        description "Core: R:core1 RP:ge-0/1/4 (ptp, isis)";<br />
        mtu 9192;<br />
        unit 0 {<br />
            family inet {<br />
                address 192.168.140.29/31;<br />
            }<br />
        }<br />
    }<br />
    ge-1/0/1 {<br />
        description "Cust: R:cust-a RP:ge-1/0/0 (srx240H)";<br />
        unit 0 {<br />
            family inet {<br />
                address 172.16.166.196/30;<br />
            }<br />
        }<br />
    }<br />
    ge-1/0/2 {<br />
        flexible-vlan-tagging;<br />
        native-vlan-id 10;<br />
        mtu 9192;<br />
        unit 10 {<br />
            description "Cust: R:cust-b (data, feed A)";<br />
            vlan-id 10;<br />
            family inet {<br />
                address 192.168.136.184/31;<br />
            }<br />
        }<br />
        unit 1001 {<br />
            description "Core: R:cust-b (cpe management)";<br />
            vlan-id 1001;<br />
            family inet {<br />
                filter {<br />
                    output Protect-cpe;<br />
                }<br />
                address 10.15.4.6/30;<br />
            }<br />
        }<br />
    }<br />
    ae0 {<br />
        description "Core: R:colo-vc2 RI:ae5";<br />
        aggregated-ether-options {<br />
            minimum-links 1;<br />
            link-speed 1g;<br />
        }<br />
        unit 0 {<br />
            family inet {<br />
                address 192.168.140.126/31;<br />
            }<br />
        }<br />
    }<br />
    lo0 {<br />
        unit 0 {<br />
            description "Core: R:primary routing loopback";<br />
            family inet {<br />
                address 192.168.128.166/32;<br />
            }
<p>            }<br />
        }<br />
    }<br />
}<br />
</p>


</code></p></config></code></p>
	
  				</p>
  				<p>
  					<a href="http://remoteur.github.io//linux/2014/02/23/junos-curly-brackets-configuration-parser/" title="JunOS config interfaces IP address parser">
  						Read More
					</a>
  				</p>
  			</div>
  		
	</div>
	<div class="post-footer">
		<div class="column-full"><a href="http://remoteur.github.io//blog">Blog archive</a></div>
	</div>
</div>

        <footer class="main-footer">
            <div class="wc-container">
                <div class="column one">
                    <h6>Few more links</h6>
<ul class="menu">
    <li><a href="http://remoteur.github.io//about">About</a></li>
    <li><a href="http://remoteur.github.io//blogroll">Blogroll</a></li>
</ul>		
                    
                </div>
                <div class="column two">
                    <h6>Follow me</h6>

<ul class="social-media">


    
    <li>
        <a title="remoteur on Twitter" 
            href="https://twitter.com/remoteur" 
            class="twitter wc-img-replace" target="_blank">Twitter</a>
    </li>   
    

    
    <li>
        <a title="remoteur on Github" 
            href="https://github.com/remoteur" 
            class="github wc-img-replace" target="_blank">Github</a>
    </li>
     

    
    <li>
        <a title="marius.catalin.31542 on Facebook" 
            href="https://facebook.com/marius.catalin.31542" 
            class="facebook wc-img-replace" target="_blank">Facebook</a>
    </li>
    

    

    

    

</ul>
                </div>
            </div>
            <p class="wc-container disclaimer">
                
Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a>
            </p>
        </footer>
        <script type="text/javascript">
          /* To avoid render blocking css */
          var cb = function() {
            var l = document.createElement('link'); l.rel = 'stylesheet';
            l.href = 'http://fonts.googleapis.com/css?family=Ubuntu+Mono&subset=latin';
            var h = document.getElementsByTagName('head')[0]; h.parentNode.insertBefore(l, h);
          };
          var raf = requestAnimationFrame || mozRequestAnimationFrame ||
              webkitRequestAnimationFrame || msRequestAnimationFrame;
          if (raf) raf(cb);
          else window.addEventListener('load', cb);
        </script>
        <!-- jQuery -->
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
        <!-- When no internet load JQuery from local -->
        <script>window.jQuery || document.write('<script src="http://remoteur.github.io//assets/js/jquery.min.js"><\/script>')</script>
        <!-- Site js -->
        <script src="http://remoteur.github.io/assets/js/all.js"></script>
        <!-- Google analytics  -->
        
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-xxxx-x']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

    </body>        
</html>
