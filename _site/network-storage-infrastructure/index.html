<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Network attached storage infrastructure</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">        
        <meta name="description" content="Harmony is a free responsive jekyll theme by Gayan Virajith and Maheshika Lakmali. Sourced on Github -  https://github.com/gayanvirajith/harmony
">
        <link rel="canonical" 
        href="https://remote-lab.net//network-storage-infrastructure">
        
        <!-- Harmony styles -->
        <link rel="stylesheet" type="text/css" href="https://remote-lab.net/assets/css/main.css">

        <!-- Modernizr js -->
        <script async src="https://remote-lab.net/assets/js/modernizr.js"></script>    

        <!-- IE Fixes -->
        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->        
    </head>
    <body class="theme-base-01">
        <header class="main-header">
            <div class="wc-container">
                <h1><a href="https://remote-lab.net/">remote-lab.net</a></h1>
                <h2>learn by doing</h2>
                <ul>
	<li>
		<a href="https://remote-lab.net">Home</a><span>/</span>
	</li>
	<li>
		<a href="https://remote-lab.net//about">About</a><span>/</span>
	</li>
	<li>
		<a href="https://remote-lab.net//blog">Blog</a><span>/</span>
	</li>
	<li>
		<a href="https://compute.remote-lab.net" target="_blank">Compute</a><span>/</span>
	</li>
	<li>
		<a href="https://github.com/remoteur/sysadmin-docs" target="_blank">Docs</a><span>/</span>
	</li>
</ul>
                
            </div>
        </header>
        <div class="page-content wc-container">
	
	<div class="post">
		<h1>Network attached storage infrastructure</h1>
		<p class="post-meta">
			
      <span class="categories">
      linux, virtualization, and storage
      </span> |
	    
	    <span class="post-date">
    	Jul 7, 2013 
	    </span>
		</p>		
		<div class="post">
			<p>Today we all need storage space and we get it in all kind of flavors: local disks, file servers on the local network, cloud storage, etc. In this post I’ll show you how you can quickly create a basic storage infrastructure that you can use for your data storage. </p>

<hr />

<p><a href="https://remote-lab.net/assets/static/storage.png"><img src="https://remote-lab.net/assets/static/storage.png" alt="storage" width="614" height="372" class="aligncenter size-full wp-image-198" /></a></p>

<p>As you may see in the diagram the topology consists of 2 clients, 2 switches and 2 storage servers. All the components in the diagram are KVM virtual machines running on a single host. You can easily create this setup on your own workstation.   Clients need to be able to access the files on the storage servers as they would on their local drives. In order to do that we can export file system paths on the storage servers by protocols such as NFS or SMB/CIFS. NFS is my favorite one so I’ll show how you can use it in this example. The clients will be basic Debian VMs running the NFS clients. </p>

<p>Hardware always fails so in order for our system to be available we need to have redundant components. The first storage server will act as the primary server, all the clients will access directly. Data on the primary server will be replicated on the second one which will act as a slave (standby). For the storage file systems we will use ZFS which is both a file system and logical volume manager. ZFS ensures data integrity checks and automatic repairs, it provides various software RAID levels and many other great features such as snapshots, compression, deduplication and replication. In addition to this ZFS is a 128-bit file system providing lots and lots of storage space. Unfortunately ZFS is licensed under Suns CDDL which is not compatible with the Linux kernel license: GPLv2. Work is currently being done for a port of ZFS for the Linux kernel ( ZFS on Linux ). In our topology the storage servers will run zfs on FreeBSD 9.1. </p>

<p>The network infrastructure is very important when we need redundant systems. Each of the storage servers will have 2 NICs grouped in a bridge connected to 2 different switches. In order to prevent bridge loops we need a loop prevention mechanism such as STP. In our environment we will use STP (802.1d) but be aware that in a production network you need other flavors of STP for reduced convergence time. The switches will run Debian as OS and Open vSwitch for the virtual switch.  </p>

<p>We can now proceed and start creating our infrastructure. I will be running Debian jessie which is the current testing release on both the host machine and the virtual machines. For the VMs communications on the hypervisor I will be using Linux bridges. Other tools that we need for the VMs management are libvirt, virt-install or virt-manager which provides a gui. </p>

<p>Installing required packages for VMs management:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@lab:~# aptitude install qemu-kvm qemu-utils libvirt-bin virtinst virt-manager bridge-utils</code></pre></div>

<p>Now let’s create a bridge for each of the vms links plus an additional one used for out of band management. eth0 is my public interface so i will use it for the management bridge.</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@lab:~# brctl addbr mgmt
root@lab:~# brctl addif mgmt eth0
root@lab:~# brctl addbr vm1-sw1
root@lab:~# brctl addbr vm2-sw2
root@lab:~# brctl addbr sw1-sw2
root@lab:~# brctl addbr sw1-st1
root@lab:~# brctl addbr sw1-st2
root@lab:~# brctl addbr sw2-st2
root@lab:~# brctl addbr sw2-st1
root@lab:~# brctl show</code></pre></div>

<p>Next thing to do is to create the virtual drives of the vms. I will use qcow2 files as they provide copy-on-write support and snapshots. You can use the qemu-img tools for creating the files. Each of the vms will be assigned one 10GB virtual drive for the OS. The storage servers will have 8 additional 260TB disks used for storage. </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@lab:/var/lib/libvirt/images# qemu-img create -f qcow2 vm1.qcow2 10G
root@lab:/var/lib/libvirt/images# qemu-img info vm1.qcow2
image: file
file format: qcow2
virtual size: 10G <span class="o">(</span><span class="m">10737418240</span> bytes<span class="o">)</span>
disk size: 136K
cluster_size: 65536
root@lab:/var/lib/libvirt/images# <span class="k">for</span> i in <span class="o">{</span>1..8<span class="o">}</span><span class="p">;</span> <span class="k">do</span> qemu-img create -f qcow2 st2.<span class="nv">$i</span>.qcow2 260T<span class="p">;</span><span class="k">done</span></code></pre></div>

<p>Now we are ready to shoot the installers. I prefer virt-install which is a CLI tool used for vms installations. You can also use virt-manager which provides a nice GUI. I will do a net install for the Debian VMs and run the installer from an attached cdrom for FreeBSD. You can use different drivers for the I/O devices. For the Linux machines I will use paravirtualized virtio drivers since they offer better performance. I noticed that FreeBSD doesn’t include native virtio support so I will use scsi drives and intel e1000 nics for it. You can even select the cpu model and what cpu features are available to the vm. The extra-args option passes the priority=low to the kernel command line which gets the Debian installer into expert mode. </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@lab:~# virt-install --name vm1 --disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/vm1.qcow2,bus<span class="o">=</span>virtio,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2 --network <span class="nv">bridge</span><span class="o">=</span>mgmt,model<span class="o">=</span>virtio --network <span class="nv">bridge</span><span class="o">=</span>vm1-sw1,model<span class="o">=</span>virtio --location<span class="o">=</span>ftp://ftp.lug.ro/debian/dists/wheezy/main/installer-amd64/ --ram<span class="o">=</span><span class="m">512</span> --cpu<span class="o">=</span>Nehalem --vcpu<span class="o">=</span><span class="m">1</span> --extra-args<span class="o">=</span><span class="s2">&quot;priority=low&quot;</span> --vnc</code></pre></div>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@lab:~# virt-install --name sw1 --disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/sw1.qcow2,bus<span class="o">=</span>virtio,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2 --network <span class="nv">bridge</span><span class="o">=</span>mgmt,model<span class="o">=</span>virtio --network <span class="nv">bridge</span><span class="o">=</span>vm1-sw1,model<span class="o">=</span>virtio --network <span class="nv">bridge</span><span class="o">=</span>sw1-st1,model<span class="o">=</span>virtio --network <span class="nv">bridge</span><span class="o">=</span>sw1-st2,model<span class="o">=</span>virtio --network <span class="nv">bridge</span><span class="o">=</span>sw1-sw2,model<span class="o">=</span>virtio --location<span class="o">=</span>ftp://ftp.lug.ro/debian/dists/wheezy/main/installer-amd64/ --ram<span class="o">=</span><span class="m">512</span> --cpu<span class="o">=</span>Nehalem --vcpu<span class="o">=</span><span class="m">1</span> --extra-args<span class="o">=</span><span class="s2">&quot;priority=low&quot;</span> --vnc</code></pre></div>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@lab:~# virt-install --name st2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.1.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.2.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.3.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.4.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.5.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.6.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.7.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--disk <span class="nv">path</span><span class="o">=</span>/var/lib/libvirt/images/st2.8.qcow2,bus<span class="o">=</span>scsi,cache<span class="o">=</span>none,format<span class="o">=</span>qcow2
--network <span class="nv">bridge</span><span class="o">=</span>mgmt,model<span class="o">=</span>e1000 --network <span class="nv">bridge</span><span class="o">=</span>sw2-st2,model<span class="o">=</span>e1000 --network <span class="nv">bridge</span><span class="o">=</span>sw2-st1,model<span class="o">=</span>e1000  --ram<span class="o">=</span><span class="m">8192</span> --cpu<span class="o">=</span>Nehalem --vcpu<span class="o">=</span><span class="m">6</span> --cdrom<span class="o">=</span>/var/lib/libvirt/images/FreeBSD-9.1-RELEASE-amd64-disc1.iso --vnc</code></pre></div>

<p>The installer should be pretty straight forward. Once they are complete we can move forward. We’ll first need to set the IP addresses for the network interfaces and install the required packages. Please note that you need to edit /etc/network/interfaces to make the IP addresses persistent. 
Quick tip: when you debug network connectivity issues always check the link status of the interfaces ( physical, virtual, bridges, etc) and get tcpdump installed on the same line with your favorite text editor. </p>

<p>NFS Clients:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@vm1:~# ip addr add 192.168.1.1/24 dev eth1
root@vm1:~# ip link <span class="nb">set </span>dev eth1 up
root@vm1:~# aptitude install nfs-common portmap</code></pre></div>

<p>Now lets’s configure the switches/bridges. One important thing we need to take care of is the STP root bridge of our topology. We need to make sure that one of the switches will be the root bridge otherwise all the traffic will be forwarded by the storage servers bridges and it’s not their job to do that.  </p>

<p>Open vSwitch:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@sw1:~# aptitude install openvswitch-switch openvswitch-common
root@sw1:~# ovs-vsctl add-br sw1
root@sw1:~# <span class="k">for</span> i in <span class="o">{</span>1..4<span class="o">}</span><span class="p">;</span><span class="k">do</span> ovs-vsctl add-port sw1 eth<span class="nv">$i</span><span class="p">;</span><span class="k">done</span><span class="p">;</span>
root@sw1:~# ovs-vsctl show
8910e761-e507-4aa7-88b5-4c26e2e2276e
    Bridge <span class="s2">&quot;sw1&quot;</span>
        Port <span class="s2">&quot;eth4&quot;</span>
            Interface <span class="s2">&quot;eth4&quot;</span>
        Port <span class="s2">&quot;sw1&quot;</span>
            Interface <span class="s2">&quot;sw1&quot;</span>
                <span class="nb">type</span>: internal
        Port <span class="s2">&quot;eth1&quot;</span>
            Interface <span class="s2">&quot;eth1&quot;</span>
        Port <span class="s2">&quot;eth2&quot;</span>
            Interface <span class="s2">&quot;eth2&quot;</span>
        Port <span class="s2">&quot;eth3&quot;</span>
            Interface <span class="s2">&quot;eth3&quot;</span>
    ovs_version: <span class="s2">&quot;1.4.2&quot;</span>
root@sw1:~# ovs-vsctl <span class="nb">set </span>bridge sw1 <span class="nv">stp_enable</span><span class="o">=</span><span class="nb">true</span>
root@sw1:~# ovs-vsctl <span class="nb">set </span>bridge sw1 other_config:stp-priority<span class="o">=</span>0x7800
root@sw1:~# ovs-ofctl show sw1
OFPT_FEATURES_REPLY <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x1<span class="o">)</span>: ver:0x1, dpid:0000e22d31067b47
n_tables:255, n_buffers:256
features: capabilities:0xc7, actions:0xfff
 1<span class="o">(</span>eth2<span class="o">)</span>: addr:52:54:00:b0:d7:e5
     config:     0
     state:      STP_FORWARD
 2<span class="o">(</span>eth2<span class="o">)</span>: addr:52:54:00:79:59:68
     config:     0
     state:      STP_FORWARD
 3<span class="o">(</span>eth3<span class="o">)</span>: addr:52:54:00:69:dc:5d
     config:     0
     state:      STP_FORWARD
 4<span class="o">(</span>eth4<span class="o">)</span>: addr:52:54:00:e1:4d:dd
     config:     0
     state:      STP_FORWARD
 LOCAL<span class="o">(</span>sw1<span class="o">)</span>: addr:e2:2d:31:06:7b:47
     config:     PORT_DOWN
     state:      LINK_DOWN
OFPT_GET_CONFIG_REPLY <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x3<span class="o">)</span>: <span class="nv">frags</span><span class="o">=</span>normal <span class="nv">miss_send_len</span><span class="o">=</span>0</code></pre></div>

<p>Storage machines networking:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:~# ifconfig bridge create
root@st1:~# ifconfig bridge0 addm em1 addm em2 up
root@st1:~# ifconfig bridge0 proto stp
root@st1:~# ifconfig bridge0 192.168.1.3 netmask 255.255.255.0
root@st1:~# ifconfig bridge0
bridge0: <span class="nv">flags</span><span class="o">=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; metric <span class="m">0</span> mtu 1500
	ether 02:d8:a2:2f:a0:00
	inet 192.168.1.3 netmask 0xffffff00 broadcast 192.168.1.255
	nd6 <span class="nv">options</span><span class="o">=</span>29&lt;PERFORMNUD,IFDISABLED,AUTO_LINKLOCAL&gt;
	id 52:54:00:04:1b:42 priority <span class="m">32768</span> hellotime <span class="m">2</span> fwddelay 15
	maxage <span class="m">20</span> holdcnt <span class="m">6</span> proto stp maxaddr <span class="m">2000</span> timeout 1200
	root id 56:ff:97:ea:f6:4b priority <span class="m">30617</span> ifcost <span class="m">20019</span> port 3
	member: em2 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">4</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role root state forwarding
	member: em1 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">3</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role alternate state discarding</code></pre></div>

<p>We can notice that one of the physical interfaces is in forwarding state and the other one is discarding. The same settings need to be done on the other machines except IP addresses, hostnames and other things that need to be unique. At this point we have the network infrastructure ready with basic connectivity ensured for all the nodes. </p>

<p>We can go ahead and do the storage configuration. As mentioned before storage1 will be the primary storage machine so we’ll start with it.</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:~# camcontrol devlist
&lt;QEMU QEMU DVD-ROM 1.1.&gt;           at scbus1 target <span class="m">0</span> lun <span class="m">0</span> <span class="o">(</span>pass0,cd0<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus2 target <span class="m">0</span> lun <span class="m">0</span> <span class="o">(</span>pass1,da0<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus2 target <span class="m">1</span> lun <span class="m">0</span> <span class="o">(</span>pass2,da1<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus2 target <span class="m">2</span> lun <span class="m">0</span> <span class="o">(</span>pass3,da2<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus2 target <span class="m">3</span> lun <span class="m">0</span> <span class="o">(</span>pass4,da3<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus2 target <span class="m">4</span> lun <span class="m">0</span> <span class="o">(</span>pass5,da4<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus2 target <span class="m">5</span> lun <span class="m">0</span> <span class="o">(</span>pass6,da5<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus2 target <span class="m">6</span> lun <span class="m">0</span> <span class="o">(</span>pass7,da6<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus3 target <span class="m">0</span> lun <span class="m">0</span> <span class="o">(</span>pass8,da7<span class="o">)</span>
&lt;QEMU QEMU HARDDISK 1.1.&gt;          at scbus3 target <span class="m">1</span> lun <span class="m">0</span> <span class="o">(</span>pass9,da8<span class="o">)</span></code></pre></div>

<p>The list shows us that we have one dvdrom (installer) and 9 drives (1 for the OS and 8 for the storage) attached. </p>

<p>ZFS:
Let’s create the ZFS storage pool. The pool will be made up of 4 mirrors of 2 x 260TB drives. ZFS mirrors are similar to RAID1 level. All the mirrors are striped so the resulting pool will have a RAID10 like fault tolerance. The total capacity of the pool will be of 1 Petabyte :)</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:~# zpool create storage mirror da1 da2 mirror da3 da4 mirror da5 da6 mirror da7 da8
root@st1:~# zpool list
NAME      SIZE  ALLOC   FREE    CAP  DEDUP  HEALTH  ALTROOT
storage  1.01P   110M  1.01P     0%  1.00x  ONLINE  -
root@st1:~# zpool status
  pool: storage
 state: ONLINE
  scan: none requested
config:
	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	  mirror-0  ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da1     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da2     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	  mirror-1  ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da3     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da4     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	  mirror-2  ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da5     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da6     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	  mirror-3  ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da7     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
	    da8     ONLINE       <span class="m">0</span>     <span class="m">0</span>     0
errors: No known data errors
root@st1:~# zfs get all storage</code></pre></div>

<p>We can now create a dataset inside the storage pool setting specific attributes. For instance, let’s create a dataset that has compression enabled:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:~# zfs create -o <span class="nv">compression</span><span class="o">=</span>on storage/compset
root@st1:~# zfs get compression storage/compset
NAME             PROPERTY     VALUE     SOURCE
storage/compset  compression  on        <span class="nb">local</span></code></pre></div>

<p>Now let’s ctually see the benefits:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:~# <span class="nb">cd</span> /storage/compset/
root@st1:compset# dd <span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>10M <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>10
10+0 records in
10+0 records out
<span class="m">10485760</span> bytes transferred in 0.014196 secs <span class="o">(</span><span class="m">738633678</span> bytes/sec
root@st1:compset# du -h 10M
512B	 10M
root@st1:compset# dd <span class="k">if</span><span class="o">=</span>/dev/random <span class="nv">of</span><span class="o">=</span>10Mr <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>10
10+0 records in
10+0 records out
<span class="m">10485760</span> bytes transferred in 0.176115 secs <span class="o">(</span><span class="m">59539266</span> bytes/sec<span class="o">)</span>
root@st1:compset# du -h 10Mr
 10M	 10Mr</code></pre></div>

<p>Let’s say we need storage space for users. We can create a dataset for that and assign each user a dataset that has an assigned quota:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:storage# zfs create storage/users
root@st1:storage# zfs create -o <span class="nv">quota</span><span class="o">=</span>10M storage/users/01
root@st1:storage# <span class="nb">cd</span> /storage/users/01
root@st1:01# dd <span class="k">if</span><span class="o">=</span>/dev/random <span class="nv">of</span><span class="o">=</span>20M <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>20
dd: 20M: Disc quota exceeded
root@st1:01# du -h 20M
 10M	20M</code></pre></div>

<p>Sanpshots:
ZFS provides snapshot functionality which is an image of the file system at the time you snapshot it. Let’s create a new data set called set, create some random files inside it and then snapshot it calling it snap1.</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:~# zfs create storage/set
root@st1:~# <span class="nb">cd</span> /storage/set/
root@st1:set# mkfile 1M 1M
root@st1:set# mkfile 5M 5M
root@st1:set# zfs snapshot storage/set@snap1
root@st1:set# ls .zfs/snapshot/snap1/
1M 5M</code></pre></div>

<p>How can we replicate all the data to the other storage machine ? ZFS enables you to transfer snapshots to another machine by piping zfs send and zfs recive which is pretty awesome. The receiving end will extract the snapshot and recreate the file system.</p>

<p>We have an empty storage pool called storage on storage2 where we’ll transfer snap1 we have just created. We’ll use netcat for raw tcp piping but you can also use ssh. </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st2:~# netcat -l -p <span class="m">9999</span> <span class="p">|</span> zfs receive storage/set
root@st1:~# zfs send storage/set@snap1 <span class="p">|</span> netcat st2 9999
root@st2:~# zfs list
NAME          USED  AVAIL  REFER  MOUNTPOINT
storage      6.14M   508T    32K  /storage
storage/set  6.03M   508T  6.03M  /storage/set
root@st2:~# ls /storage/set/
1M 5M</code></pre></div>

<p>You can also send incremental data using zfs send. We’ll create an additional file in /storage/set, create a snapshot and transfer only the differences between the second and the first snapshot. We’ll use ssh this time:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:set# mkfile 10M 10M
root@st1:set# zfs snapshot storage/set@snap2
root@st1:set# zfs send -i storage/set@snap1 storage/set@snap2  <span class="p">|</span> ssh st2 zfs receive storage/set
root@st2:~# ls /storage/set/
10M 1M  5M</code></pre></div>

<p>What happens if we delete a file ? </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:set# rm * <span class="o">&amp;&amp;</span> touch Lala
root@st1:set# zfs snapshot storage/set@snap3
root@st1:set# zfs send -i storage/set@snap2 storage/set@snap3  <span class="p">|</span> ssh st2 zfs receive storage/set
root@st2:~# ls /storage/set/
Lala</code></pre></div>

<p>Using the great snapshot and zfs send and receive features we could easily set up a cron job that does periodic incremental transfers thus having all the data on storage1 replicated on storage2. 
Now that we have all the storage prepared let’s mount it on the clients by NFS. On the storage server prepare the /etc/exports file:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@st1:set# cat /etc/exports
/storage/set -maproot<span class="o">=</span>root 192.168.1.1
root@st1:set# /etc/rc.d/mountd onereload
root@vm1:~# mount st1:/storage/set /mnt -v
root@vm1:~# df -h <span class="p">|</span> grep st1
Filesystem                                              Size  Used Avail Use% Mounted on
st1:/storage/set                                       1016T     <span class="m">0</span> 1016T   0% /mnt</code></pre></div>

<p>Now let’s go for a failover test of the bridged interfaces on the storage machine. We’ll start writing a random file using dd in vm1:/mnt, shutdown the forwarding interface on storage1 and wait to see what happens.</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@vm1:~# dd <span class="k">if</span><span class="o">=</span>/dev/vda <span class="nv">of</span><span class="o">=</span>/root/random <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>10
root@vm1:~# md5sum /root/random
9662731c837501f21938b04e09aa02b3  random
root@vm1:~# dd <span class="k">if</span><span class="o">=</span>/root/random <span class="nv">of</span><span class="o">=</span>/mnt/random
root@st1:set# ifconfig bridge0
bridge0: <span class="nv">flags</span><span class="o">=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; metric <span class="m">0</span> mtu 1500
	ether 02:d8:a2:2f:a0:00
	inet 192.168.1.3 netmask 0xffffff00 broadcast 192.168.1.255
	nd6 <span class="nv">options</span><span class="o">=</span>29&lt;PERFORMNUD,IFDISABLED,AUTO_LINKLOCAL&gt;
	id 52:54:00:04:1b:42 priority <span class="m">32768</span> hellotime <span class="m">2</span> fwddelay 15
	maxage <span class="m">20</span> holdcnt <span class="m">6</span> proto stp maxaddr <span class="m">2000</span> timeout 1200
	root id 56:ff:97:ea:f6:4b priority <span class="m">30617</span> ifcost <span class="m">20000</span> port 4
	member: em2 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">4</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role root state forwarding
	member: em1 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">3</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role alternate state discarding
root@st1:set# ifconfig em2 down
root@st1:set# ifconfig bridge0
bridge0: <span class="nv">flags</span><span class="o">=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; metric <span class="m">0</span> mtu 1500
	ether 02:d8:a2:2f:a0:00
	inet 192.168.1.3 netmask 0xffffff00 broadcast 192.168.1.255
	nd6 <span class="nv">options</span><span class="o">=</span>29&lt;PERFORMNUD,IFDISABLED,AUTO_LINKLOCAL&gt;
	id 52:54:00:04:1b:42 priority <span class="m">32768</span> hellotime <span class="m">2</span> fwddelay 15
	maxage <span class="m">20</span> holdcnt <span class="m">6</span> proto stp maxaddr <span class="m">2000</span> timeout 1200
	root id 56:ff:97:ea:f6:4b priority <span class="m">30617</span> ifcost <span class="m">20019</span> port 3
	member: em2 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">4</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role disabled state discarding
	member: em1 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">3</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role root state learning
root@st1:set# ifconfig bridge0
bridge0: <span class="nv">flags</span><span class="o">=</span>8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; metric <span class="m">0</span> mtu 1500
	ether 02:d8:a2:2f:a0:00
	inet 192.168.1.3 netmask 0xffffff00 broadcast 192.168.1.255
	nd6 <span class="nv">options</span><span class="o">=</span>29&lt;PERFORMNUD,IFDISABLED,AUTO_LINKLOCAL&gt;
	id 52:54:00:04:1b:42 priority <span class="m">32768</span> hellotime <span class="m">2</span> fwddelay 15
	maxage <span class="m">20</span> holdcnt <span class="m">6</span> proto stp maxaddr <span class="m">2000</span> timeout 1200
	root id 56:ff:97:ea:f6:4b priority <span class="m">30617</span> ifcost <span class="m">20019</span> port 3
	member: em2 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">4</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role disabled state discarding
	member: em1 <span class="nv">flags</span><span class="o">=</span>1c7&lt;LEARNING,DISCOVER,STP,AUTOEDGE,PTP,AUTOPTP&gt;
	        ifmaxaddr <span class="m">0</span> port <span class="m">3</span> priority <span class="m">128</span> path cost <span class="m">20000</span> proto stp
	        role root state forwarding</code></pre></div>

<p>The result:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">root@vm1:~# dd <span class="k">if</span><span class="o">=</span>/root/random <span class="nv">of</span><span class="o">=</span>/mnt/random
10+0 records in
10+0 records out
<span class="m">10485760</span> bytes <span class="o">(</span><span class="m">10</span> MB<span class="o">)</span> copied, 56.1668 s, <span class="m">187</span> kB/s
root@st1:set# md5 random
MD5 <span class="o">(</span>random<span class="o">)</span> <span class="o">=</span> 9662731c837501f21938b04e09aa02b</code></pre></div>

<p>Transfer was very slow but your data is uncorrupted on the remote storage. 
I hope you enjoyed this long tutorial :) Let me know if you any questions or other observations and I’ll be more than happy to answer. </p>

		</div>
	</div>


	
	<div class="related">
		<h4>Related Posts</h2>
		<ul class="posts">
		    
		    <li>
			  <span>05 Apr 2015 &raquo;</span>
			  <a href="https://remote-lab.net//getting-started-with-docker">Getting started with Docker and the wonders of Open Source</a>
		    </li>
		    
		    <li>
			  <span>24 Feb 2015 &raquo;</span>
			  <a href="https://remote-lab.net//opsf-on-ios-with-ansible">OSPF lab provisioning on IOS with Ansible</a>
		    </li>
		    
		    <li>
			  <span>12 Oct 2014 &raquo;</span>
			  <a href="https://remote-lab.net//sdn-intro-basic-with-ovs-and-pox">SDN Intro: Basic L2 connectivity by using OVS and POX</a>
		    </li>
		    
		</ul>
	</div>
	

	<div class="post-footer">
		<div class="column-1">
			
				<a href="https://remote-lab.net//dynamic-dns-using-your-own-domain"><< Older</a>
			
		</div>
		<div class="column-2"><a href="https://remote-lab.net// ">Home</a></div>
		<div class="column-3">
			
				<a href="https://remote-lab.net//cisco-devices-ssh-autologin">Newer >></a>
			
		</div>
	</div>
</div>
 

        <footer class="main-footer">
            <div class="wc-container">
                <div class="column one">
                    <h6>Few more links</h6>
<ul class="menu">
    <li><a href="https://remote-lab.net//about">About</a></li>
    <li><a href="https://remote-lab.net//blogroll">Blogroll</a></li>
</ul>		
                    
                </div>
                <div class="column two">
                    <h6>Follow me</h6>

<ul class="social-media">


    
    <li>
        <a title="remoteur on Twitter" 
            href="https://twitter.com/remoteur" 
            class="twitter wc-img-replace" target="_blank">Twitter</a>
    </li>   
    

    
    <li>
        <a title="remoteur on Github" 
            href="https://github.com/remoteur" 
            class="github wc-img-replace" target="_blank">Github</a>
    </li>
     

    
    <li>
        <a title="marius.catalin.31542 on Facebook" 
            href="https://facebook.com/marius.catalin.31542" 
            class="facebook wc-img-replace" target="_blank">Facebook</a>
    </li>
    

    

    

    

</ul>
                </div>
            </div>
            <p class="wc-container disclaimer">
                
Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a>
            </p>
        </footer>
        <script type="text/javascript">
          /* To avoid render blocking css */
          var cb = function() {
            var l = document.createElement('link'); l.rel = 'stylesheet';
            l.href = 'https://fonts.googleapis.com/css?family=Ubuntu+Mono&subset=latin';
            var h = document.getElementsByTagName('head')[0]; h.parentNode.insertBefore(l, h);
          };
          var raf = requestAnimationFrame || mozRequestAnimationFrame ||
              webkitRequestAnimationFrame || msRequestAnimationFrame;
          if (raf) raf(cb);
          else window.addEventListener('load', cb);
        </script>
        <!-- jQuery -->
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
        <!-- When no internet load JQuery from local -->
        <script>window.jQuery || document.write('<script src="https://remote-lab.net//assets/js/jquery.min.js"><\/script>')</script>
        <!-- Site js -->
        <script src="https://remote-lab.net/assets/js/all.js"></script>
        <!-- Google analytics  -->
        
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-xxxx-x']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

    </body>        
</html>
